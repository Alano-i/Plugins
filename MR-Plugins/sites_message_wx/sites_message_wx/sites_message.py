#!/usr/bin/env python3
from mbot.core.plugins import plugin
from mbot.core.plugins import PluginContext, PluginMeta
from mbot.openapi import mbot_api
from typing import Dict, Any
from urllib.parse import urljoin
from bs4 import BeautifulSoup, SoupStrainer
import time
import random
import re
import os
import requests
import logging
import yaml
from requests.adapters import HTTPAdapter
from requests.packages.urllib3.util.retry import Retry
from datetime import datetime
server = mbot_api
_LOGGER = logging.getLogger(__name__)
site_list = server.site.list()
message_skip_list = ['mteam', 'pttime' 'mikanani', 'acgrip', 'sukebei', 'exoticaz', 'filelist', 'hares', 'iptorrents','rarbg']
notice_skip_list = ['mteam', 'pttime', 'mikanani', 'acgrip', 'sukebei', 'exoticaz', 'ttg', 'filelist', 'hares','iptorrents', 'rarbg']

@plugin.after_setup
def after_setup(plugin_meta: PluginMeta, config: Dict[str, Any]):
    global words,user_id,wecom_proxy_url,message_to_uid,qywx_channel_extra,corpid_extra,corpsecret_extra,agentid_extra,touser_extra
    message_to_uid = config.get('uid')
    qywx_channel_extra = config.get('qywx_channel_extra')
    corpid_extra = config.get('corpid_extra')
    corpsecret_extra = config.get('corpsecret_extra')
    agentid_extra = config.get('agentid_extra')
    touser_extra = config.get('touser_extra')
    words = config.get('word_ignore')
    wecom_proxy_url = config.get('wecom_proxy_url')
    if message_to_uid:
        user_id = message_to_uid[0]
    else:
         _LOGGER.error('ã€ŒPTç«™å†…ä¿¡å’Œå…¬å‘Šæ¨é€ã€è·å–æ¨é€ç”¨æˆ·å¤±è´¥ï¼Œå¯èƒ½æ˜¯è®¾ç½®äº†æ²¡ä¿å­˜æˆåŠŸæˆ–è€…è¿˜æœªè®¾ç½®')
         user_id = ''

@plugin.config_changed
def config_changed(config: Dict[str, Any]):
    global words,user_id,wecom_proxy_url,message_to_uid,qywx_channel_extra,corpid_extra,corpsecret_extra,agentid_extra,touser_extra
    _LOGGER.info('ã€ŒPTç«™å†…ä¿¡å’Œå…¬å‘Šæ¨é€ã€é…ç½®å‘ç”Ÿå˜æ›´ï¼ŒåŠ è½½æ–°è®¾ç½®ï¼')
    message_to_uid = config.get('uid')
    qywx_channel_extra = config.get('qywx_channel_extra')
    corpid_extra = config.get('corpid_extra')
    corpsecret_extra = config.get('corpsecret_extra')
    agentid_extra = config.get('agentid_extra')
    touser_extra = config.get('touser_extra')
    words = config.get('word_ignore')
    wecom_proxy_url = config.get('wecom_proxy_url')
    if message_to_uid:
        user_id = message_to_uid[0]
    else:
         _LOGGER.error('ã€ŒPTç«™å†…ä¿¡æ¨é€ã€è·å–æ¨é€ç”¨æˆ·å¤±è´¥ï¼Œå¯èƒ½æ˜¯è®¾ç½®äº†æ²¡ä¿å­˜æˆåŠŸæˆ–è€…è¿˜æœªè®¾ç½®')
         user_id = ''

@plugin.task('sites_message_wx', 'å®šæ—¶è·å–ç«™å†…ä¿¡å’Œå…¬å‘Š', cron_expression='0 9,19 * * *')
def task():
    time.sleep(random.randint(1, 600))
    _LOGGER.info('å¼€å§‹è·å–ç«™å†…ä¿¡å’Œå…¬å‘Š')
    # site_notice()
    main()
    _LOGGER.info('æ‰€æœ‰ç«™ç‚¹ç«™å†…ä¿¡å’Œå…¬å‘Šè·å–å®Œæˆ')

@plugin.on_event(
    bind_event=['SiteSearchComplete', 'SiteListComplete'], order=1)
def on_site_search_complete(ctx: PluginContext, event_type: str, data: Dict):
    site_id = data.get('site_id')
    site_name = data.get('site_name')
    site_domain = data.get('domain')
    html = data.get('html')
    if site_id in message_skip_list:
        return
    if site_id == 'ssd':
        message_notify_box = 'a[style^="display"]'
    else:
        message_notify_box = 'a[href="messages.php"] > font'
    soup_tmp = SoupStrainer("a", href="messages.php")
    soup = BeautifulSoup(html, 'html.parser', parse_only=soup_tmp).select(message_notify_box)
    if soup:
        push_wx, access_token, agentid, touser, wecom_api_url = is_push_to_wx()
        for site in site_list:
            if site.site_name == site_name:
                site_cookie = site.cookie
                site_proxies = site.proxies
                site_user_agent = site.user_agent
                sites_message(site_domain, site_name, site_cookie, site_proxies, site_user_agent, site_id, push_wx, access_token, agentid, touser, wecom_api_url)
                break

def sites_message_by_manual(push_wx, access_token, agentid, touser, wecom_api_url):
    # push_wx, access_token, agentid, touser, wecom_api_url = is_push_to_wx()
    for site in site_list:
        site_id = site.site_id
        if site_id in message_skip_list:
            continue
        site_name = site.site_name
        site_domain = site.domain
        site_cookie = site.cookie
        site_proxies = site.proxies
        site_user_agent = site.user_agent
        sites_message(site_domain, site_name, site_cookie, site_proxies, site_user_agent, site_id, push_wx, access_token, agentid, touser, wecom_api_url)

def sites_message(site_domain, site_name, site_cookie, site_proxies, site_user_agent, site_id, push_wx, access_token, agentid, touser, wecom_api_url):
    _LOGGER.info(f'å¼€å§‹è·å–ã€Œ{site_name}ã€ç«™å†…ä¿¡')
    try:
        message_list, messages_url, messages_item_url, count = get_nexusphp_message(site_name, site_domain, site_cookie, site_proxies, site_user_agent)
        if message_list:
            image_path = f'/data/plugins/sites_message_wx/pic/{site_id}.gif'
            try:
                if not os.path.exists(image_path):
                    image_path = f'/data/plugins/sites_message_wx/pic/msg_default.gif'
            except Exception as e:
                _LOGGER.error(f'æ£€æŸ¥æ–‡ä»¶æ˜¯å¦å­˜åœ¨æ—¶å‘ç”Ÿå¼‚å¸¸ï¼ŒåŸå› ï¼š{e}')
            if count > 1:
                wecom_title = f'ğŸ’Œ {site_name}: {count} æ¡ç«™å†…æ–°ä¿¡æ¯'
                wecom_content_m = ''.join(message_list)
                wecom_content_m = wecom_content_m.replace('<line>', '')
                wecom_content_m = wecom_content_m.strip('\n')
                wecom_content = wecom_content_m.replace('\n', '<br/>')
                wecom_digest = re.sub(r'<.*?>', '', wecom_content_m) 
                content_source_url = messages_url
            else:
                wecom_title = message_list[0].split('<line>\n')[0]
                wecom_content = message_list[0].split('<line>\n')[1]
                wecom_content = wecom_content.strip('\n')
                wecom_title = wecom_title.replace('\n', '')
                wecom_title = re.sub(r'<.*?>', '', wecom_title)
                wecom_title = f'ğŸ’Œ {site_name}: {wecom_title}'
                wecom_title = wecom_title.replace('ğŸ’¬ ', '')
                wecom_title = wecom_title.replace('ä½ çš„ç§å­/å¸–å­æ”¶åˆ°é­”åŠ›å€¼å¥–åŠ±', 'æ”¶åˆ°é­”åŠ›å€¼å¥–åŠ±')
                wecom_title = wecom_title.replace('æ‚¨æ­£åœ¨ä¸‹è½½æˆ–åšç§çš„ç§å­è¢«åˆ é™¤', 'ç§å­è¢«åˆ é™¤')
                content_source_url = messages_item_url
                wecom_digest = re.sub(r'<.*?>', '', wecom_content)
            wecom_content = wecom_content.replace('\n', '<br/>')
            if push_wx:
                thumb_media_id = get_media_id(site_name, access_token, image_path)
                result = push_msg_wx(access_token, touser, agentid, wecom_title, thumb_media_id, content_source_url, wecom_digest, wecom_content, wecom_api_url)
                _LOGGER.info(f'ã€Œ{site_name}ã€ğŸ’Œ æœ‰æ–°ç«™å†…ä¿¡ï¼Œä¼ä¸šå¾®ä¿¡æ¨é€ç»“æœ: {result}')
            else:
                pic_url = 'https://raw.githubusercontent.com/Alano-i/wecom-notification/main/MR-Plugins/sites_message_wx/sites_message_wx/pic/msg_default.gif'
                result = push_msg_mr(wecom_title, wecom_digest, pic_url, content_source_url)
                _LOGGER.info(f'ã€Œ{site_name}ã€ğŸ’Œ æœ‰æ–°ç«™å†…ä¿¡ï¼Œè‡ªé€‰æ¨é€é€šé“æ¨é€ç»“æœ: {result}')
        else:
            _LOGGER.info(f'ã€Œ{site_name}ã€æ— æœªè¯»ç«™å†…ä¿¡ï¼Œæˆ–é€šè¿‡å…³é”®è¯è¿‡æ»¤åæ²¡æœ‰éœ€è¦æ¨é€çš„æ–°æ¶ˆæ¯')
    except Exception as e:
        _LOGGER.error(f'è·å–ã€Œ{site_name}ã€ç«™å†…ä¿¡å¤±è´¥ï¼ŒåŸå› ï¼š{e}')
        return

def site_notice(push_wx, access_token, agentid, touser, wecom_api_url):
    # push_wx, access_token, agentid, touser, wecom_api_url = is_push_to_wx()
    for site in site_list:
        site_id = site.site_id
        site_name = site.site_name
        site_url = site.domain
        if not site_id:
            continue
        if site_id in notice_skip_list:
            continue
        _LOGGER.info(f'å¼€å§‹è·å–ã€Œ{site.site_name}ã€ç«™ç‚¹å…¬å‘Š')
        try:
            notice_list = get_nexusphp_notice(site.site_name, site.site_id, site.domain, site.cookie, site.proxies, site.user_agent)
            if notice_list:
                image_path = f'/data/plugins/sites_message_wx/pic/{site_id}.gif'
                try:
                    if not os.path.exists(image_path):
                        image_path = f'/data/plugins/sites_message_wx/pic/notice_default.gif'
                except Exception as e:
                    _LOGGER.error(f'æ£€æŸ¥æ–‡ä»¶æ˜¯å¦å­˜åœ¨æ—¶å‘ç”Ÿå¼‚å¸¸ï¼ŒåŸå› ï¼š{e}')
                wecom_title = f'ğŸ“¢ {site_name}: {notice_list[1]}'
                wecom_content_m = f'<b><big>{notice_list[0]}</b></big>\n<small>{notice_list[2]}</small>'
                wecom_content = wecom_content_m.replace('\n', '<br/>')
                wecom_digest = re.sub(r'<.*?>', '', wecom_content_m)
                content_source_url = f'{site_url}'
                if push_wx:
                    thumb_media_id = get_media_id(site_name, access_token, image_path)
                    result = push_msg_wx(access_token, touser, agentid, wecom_title, thumb_media_id, content_source_url, wecom_digest, wecom_content, wecom_api_url)
                    _LOGGER.info(f'ã€Œ{site_name}ã€ğŸ“¢ æœ‰æ–°å…¬å‘Šï¼Œä¼ä¸šå¾®ä¿¡æ¨é€ç»“æœ: {result}')
                else:
                    pic_url = 'https://raw.githubusercontent.com/Alano-i/wecom-notification/main/MR-Plugins/sites_message_wx/sites_message_wx/pic/notice_default.gif'
                    result = push_msg_mr(wecom_title, wecom_digest, pic_url, content_source_url)
                    _LOGGER.info(f'ã€Œ{site_name}ã€ğŸ“¢ æœ‰æ–°å…¬å‘Šï¼Œè‡ªé€‰æ¨é€é€šé“æ¨é€ç»“æœ: {result}')
            else:
                _LOGGER.info(f'ã€Œ{site_name}ã€æ— æ–°å…¬å‘Š')
        except Exception as e:
            _LOGGER.error(f'è·å–ã€Œ{site.site_name}ã€ç«™ç‚¹å…¬å‘Šå¤±è´¥ï¼ŒåŸå› ï¼š{e}')
            continue

def get_nexusphp_message(site_name, site_url, cookie, proxies, user_agent):
    message_list = []
    sms_title = ''
    element_body = ''
    messages_item_url = ''
    message_url = ''
    count = 0
    unread_selector = 'td > img[alt="Unread"]'
    body_selector = 'td[colspan*="2"]'
    if proxies:
        if proxies.startswith('http'):
            proxies = {
                'http': proxies
            }
        elif proxies.startswith('socks5'):
            proxies = {
                'socks5': proxies
            }
    else:
        proxies = None
    message_url = 'messages.php?action=viewmailbox&box=1&unread=1'
    messages_url = urljoin(site_url, message_url)
    headers = {
        'cookie': cookie,
        'user-agent': user_agent,
    }
    session = requests.Session()
    retry = Retry(connect=3, backoff_factor=0.5)
    adapter = HTTPAdapter(max_retries=retry)
    session.mount('https://', adapter)
    response = session.request("GET", messages_url, headers=headers, proxies=proxies, timeout=30).text
    soup_tmp = SoupStrainer("form", {"action": "messages.php"})
    soup = BeautifulSoup(response, 'html.parser', parse_only=soup_tmp)
    unread_list = soup.select(unread_selector)
    messages_item_url = ''
    for unread_item in unread_list:
        td = unread_item.parent.next_sibling.next_sibling
        sms_title = td.text
        sms_title = f'ğŸ’¬ {sms_title}'
        href = td.a['href']
        messages_item_url = urljoin(site_url, href)
        message_res = requests.request("GET", messages_item_url, headers=headers, proxies=proxies, timeout=30).text
        message_soup_tmp = SoupStrainer("td", {"colspan": "2"})
        message_soup = BeautifulSoup(message_res, 'html.parser', parse_only=message_soup_tmp)
        element_body = message_soup.select(body_selector)[0].text.strip()
        element_body = re.sub(r'[\n\r]+', '\n', element_body)
        element_body = re.sub(r'\[.*?\]', '', element_body)
        count = count + 1
        caption_content = f'<b><big>{sms_title.strip()}</b></big><line>\n<small>{element_body}</small>\n\n'
        message_list.append(caption_content)
    if message_list:
        _LOGGER.info(f'ã€Œå…³é”®å­—è¿‡æ»¤å‰ï¼Œæœªè¯»ç«™å†…ä¿¡æ•°é‡ã€{count}')
        message_list,count = word_ignore(site_name, message_list,count)
        _LOGGER.info(f'ã€Œå…³é”®å­—è¿‡æ»¤åï¼Œæœªè¯»ç«™å†…ä¿¡æ•°é‡ã€{count}')
    return message_list, messages_url, messages_item_url, count

def get_nexusphp_notice(site_name, site_id, site_url, cookie, proxies, user_agent):
    sites_notice_selector = {
        'putao': {
            'notice_box_selector': 'td',
            'notice_box_attributes': {'class': 'text'},
            'notice_title_selector': 'td.text > ul > a',
            'notice_content_selector': 'td.text > ul > div',
        },
        'ssd': {
            'notice_box_selector': 'td',
            'notice_box_attributes': {'class': 'text'},
            'notice_title_selector': 'td.text > div > div:nth-child(1) > a',
            'notice_content_selector': 'td.text > div > div:nth-child(1) > div',
        },
        'hdchina': {
            'notice_box_selector': 'div',
            'notice_box_attributes': {'class': 'announcebox'},
            'notice_title_selector': 'div.announcebox > div.announce > h4',
            'notice_content_selector': 'div.announcebox > div.announce > h3',
        },
        'nexusphp': {
            'notice_box_selector': 'td',
            'notice_box_attributes': {'class': 'text'},
            'notice_title_selector': 'td.text > div > a',
            'notice_content_selector': 'td.text > div > div',
        }
    }
    if site_id not in sites_notice_selector.keys():
        site_id = 'nexusphp'
    notice_box_selector = sites_notice_selector[site_id].get('notice_box_selector')
    notice_box_attributes = sites_notice_selector[site_id].get('notice_box_attributes')
    notice_title_selector = sites_notice_selector[site_id].get('notice_title_selector')
    notice_content_selector = sites_notice_selector[site_id].get('notice_content_selector')
    notice_list = []
    xxx = ''
    notice_date_title = ''
    notice_content = ''
    notice_title = ''
    notice_date = ''
    notice_url = 'index.php'
    notice_url = urljoin(site_url, notice_url)
    headers = {
        'cookie': cookie,
        'user-agent': user_agent,
    }
    if proxies:
        if proxies.startswith('http'):
            proxies = {
                'http': proxies
            }
        elif proxies.startswith('socks5'):
            proxies = {
                'socks5': proxies
            }
    else:
        proxies = None
    session = requests.Session()
    retry = Retry(connect=3, backoff_factor=0.5)
    adapter = HTTPAdapter(max_retries=retry)
    session.mount('https://', adapter)
    response = session.request("GET", notice_url, headers=headers, proxies=proxies, timeout=30).text  
    soup_tmp = SoupStrainer(notice_box_selector, notice_box_attributes)
    soup = BeautifulSoup(response, 'html.parser', parse_only=soup_tmp)
    notice_date_title = soup.select(notice_title_selector)
    if notice_date_title:
        notice_date_title = notice_date_title[0].text.strip()
        try:
            notice_date, notice_title = notice_date_title.split(' - ')
        except Exception as e:
            notice_date, notice_title = notice_date_title.split(' -')
        notice_date = notice_date.replace('.', '-')
        notice_date = f'{notice_date} å…¬å‘Š'
    notice_content = soup.select(notice_content_selector)
    if notice_content:
        notice_content = notice_content[0].text.strip()
        notice_content = notice_content.strip()
        notice_content = re.sub(r'[\n\r]+', '\n', notice_content)
        notice_content = re.sub(r'\[.*?\]', '', notice_content)
    
    if notice_date and not notice_content:
        notice_content = 'æ— æ–‡å­—å†…å®¹ï¼Œå¯èƒ½æ˜¯å›¾ç‰‡å…¬å‘Šï¼'

    if notice_date or notice_title or notice_content:
        notice_list = [notice_date, notice_title, notice_content]
        new_notice = {'date':notice_date, 'title':notice_title, 'content':notice_content}
        # new_notice = {'date':'notice_date', 'title':'notice_title', 'content':'notice_content'}
        if new_notice != server.common.get_cache('site_notice', site_name):
            server.common.set_cache('site_notice', site_name, new_notice)
        else:
            _LOGGER.info(f'ã€Œ{site_name}ã€è·å–åˆ°çš„ã€Œæœ€æ–°å…¬å‘Šã€å’Œã€Œç¼“å­˜å…¬å‘Šã€ç›¸åŒï¼Œä¸æ¨é€')
            notice_list = ''
    else:
        notice_list = ''
    xxx = server.common.get_cache('site_notice', site_name)
    _LOGGER.info(f'ã€Œ{site_name}ã€å…¬å‘Šçš„æœ€æ–°ç¼“å­˜ä¸º{xxx}')
    return notice_list

def word_ignore(site_name, message_list, count):
    word, hit = [], []
    if words:
        word = words.split(',')
        _LOGGER.info(f'ã€Œè®¾å®šè¿‡æ»¤å…³é”®è¯ã€{word}')
        for item in message_list:
            for i in word:
                if i in item:
                    hit.append(item)
                    break
        for hit_item in hit:
            message_list.remove(hit_item)
            count = count - 1
            _LOGGER.error(f'ã€Œ{site_name}ã€æœªè¯»ç«™å†…ä¿¡è§¦å‘å…³é”®è¯è¿‡æ»¤ï¼Œå°†å±è”½æ­¤æ¡æ¶ˆæ¯ï¼Œç›¸å…³æ¶ˆæ¯ä¸ä¼šæ¨é€ï¼')
        if not hit:
            _LOGGER.info(f'ã€Œ{site_name}ã€æœªè¯»ç«™å†…ä¿¡æœªè§¦å‘å…³é”®è¯è¿‡æ»¤')
    else:
        _LOGGER.info(f'æœªè®¾å®šè¿‡æ»¤å…³é”®è¯')
    return message_list,count

def is_push_to_wx():
    push_wx = True
    extra_flag = True
    wecom_api_url = 'https://qyapi.weixin.qq.com'
    access_token = ''
    agentid = ''
    touser = ''
    if qywx_channel_extra:
        if corpid_extra and agentid_extra and corpsecret_extra and touser_extra:
            corpid = corpid_extra
            agentid = agentid_extra
            corpsecret = corpsecret_extra
            touser = touser_extra
            _LOGGER.error(f'è®¾ç½®çš„ç‹¬ç«‹å¾®ä¿¡åº”ç”¨å‚æ•°:ã€Œagentid: {agentid} corpid: {corpid} corpsecret: {corpsecret} touser: {touser}ã€')
        else:
            _LOGGER.error(f'è®¾ç½®çš„ç‹¬ç«‹å¾®ä¿¡åº”ç”¨å‚æ•°ä¸å®Œæ•´ï¼Œå°†é‡‡ç”¨é»˜è®¤æ¶ˆæ¯é€šé“æ¨é€')
            push_wx = False
            extra_flag = False
    if user_id and not qywx_channel_extra:
        corpid, agentid, corpsecret = get_qywx_info()
        touser = server.user.get(user_id).qywx_user
        _LOGGER.info(f'è·å–åˆ° MR ç³»ç»Ÿä¸»å¹²è®¾ç½®çš„çš„ä¼ä¸šå¾®ä¿¡ä¿¡æ¯:ã€Œagentid: {agentid} corpid: {corpid} corpsecret: {corpsecret} touser: {touser}ã€')
        if not agentid or not corpid or not corpsecret or not touser:
            _LOGGER.error('ä¼ä¸šå¾®ä¿¡ä¿¡æ¯è·å–å¤±è´¥æˆ–å¡«å†™ä¸å®Œæ•´')
            _LOGGER.error('åœ¨è®¾ç½®-è®¾ç½®ä¼ä¸šå¾®ä¿¡é¡µè®¾ç½®ï¼šã€Œagentidã€ï¼Œã€Œcorpidã€ï¼Œã€Œcorpsecretã€')
            _LOGGER.error('åœ¨ç”¨æˆ·ç®¡ç†é¡µè®¾ç½®å¾®ä¿¡è´¦å·ï¼Œè·å–æ–¹æ³•å‚è€ƒ: https://alanoo.notion.site/thumb_media_id-64f170f7dcd14202ac5abd6d0e5031fb')
            _LOGGER.error('æœ¬æ’ä»¶é€‰ç”¨å¾®ä¿¡é€šé“æ¨é€æ¶ˆæ¯æ•ˆæœæœ€ä½³ï¼Œä½†ç°åœ¨æ²¡è·å–åˆ°ï¼Œå°†é‡‡ç”¨é»˜è®¤æ¶ˆæ¯é€šé“æ¨é€')
            _LOGGER.error('é»˜è®¤æ¶ˆæ¯é€šé“æ¨é€ï¼šæ¯ä¸ªç«™ç‚¹å°é¢å›¾æ— æ³•ä¸€ç«™ä¸€å›¾ï¼Œéƒ½æ˜¯ç»Ÿä¸€çš„')
            push_wx = False
    elif not user_id and not qywx_channel_extra:
        _LOGGER.error('æœªè®¾ç½®æ¨é€äººï¼Œä¹Ÿæ²¡æœ‰è®¾ç½®ç‹¬ç«‹å¾®ä¿¡åº”ç”¨å‚æ•°ï¼Œå°†é‡‡ç”¨é»˜è®¤æ¶ˆæ¯é€šé“æ¨é€')
        _LOGGER.error('é»˜è®¤æ¶ˆæ¯é€šé“æ¨é€ï¼šæ¯ä¸ªç«™ç‚¹å°é¢å›¾æ— æ³•ä¸€ç«™ä¸€å›¾ï¼Œéƒ½æ˜¯ç»Ÿä¸€çš„')
        push_wx = False
    if (push_wx or qywx_channel_extra) and extra_flag:
        if wecom_proxy_url:
            _LOGGER.info(f'è®¾ç½®äº†å¾®ä¿¡ç™½åå•ä»£ç†ï¼Œåœ°å€æ˜¯ï¼š{wecom_proxy_url}')
            wecom_api_url = wecom_proxy_url
        else:
            _LOGGER.info('æœªè®¾ç½®å¾®ä¿¡ç™½åå•ä»£ç†ï¼Œä½¿ç”¨å®˜æ–¹ api åœ°å€: https://qyapi.weixin.qq.com')
        push_wx, access_token = getToken(corpid, corpsecret, wecom_api_url)
    return push_wx, access_token, agentid, touser, wecom_api_url

def get_qywx_info():
    try:
        yml_file = "/data/conf/base_config.yml"
        with open(yml_file, encoding='utf-8') as f:
            yml_data = yaml.load(f, Loader=yaml.FullLoader)
        for channel in yml_data['notify_channel']:
            if channel['enable']:
                agentid = channel.get('agentid')
                corpid = channel.get('corpid')
                corpsecret = channel.get('corpsecret')
                return corpid, agentid, corpsecret
    except Exception as e:
        _LOGGER.error(f'è·å–ã€Œä¼ä¸šå¾®ä¿¡é…ç½®ä¿¡æ¯ã€é”™è¯¯ï¼Œå¯èƒ½ MR ä¸­å¡«å†™çš„ä¿¡æ¯æœ‰è¯¯æˆ–ä¸å…¨: {e}')
        pass
    return '','',''

def getToken(corpid, corpsecret, wecom_api_url):
    url = wecom_api_url + "/cgi-bin/gettoken?corpid=" + corpid + "&corpsecret=" + corpsecret
    MAX_RETRIES = 3
    for i in range(MAX_RETRIES):
        try:
            r = requests.get(url)
            break
        except requests.RequestException as e:
            _LOGGER.error(f'å¤„ç†å¼‚å¸¸ï¼ŒåŸå› ï¼š{e}')
            time.sleep(2)
    if r.json()['errcode'] == 0:
        access_token = r.json()['access_token']
        return True, access_token
    else:
        _LOGGER.error('è¯·æ±‚ä¼ä¸šå¾®ä¿¡ã€Œaccess_tokenã€å¤±è´¥,è¯·æ£€æŸ¥ä¼ä¸šå¾®ä¿¡å„ä¸ªå‚æ•°æ˜¯å¦è®¾ç½®æ­£ç¡®ï¼Œå°†é‡‡ç”¨é»˜è®¤æ¶ˆæ¯é€šé“æ¨é€ï¼')
        _LOGGER.error('é»˜è®¤æ¶ˆæ¯é€šé“æ¨é€ï¼šæ¯ä¸ªç«™ç‚¹å°é¢å›¾æ— æ³•ä¸€ç«™ä¸€å›¾ï¼Œéƒ½æ˜¯ç»Ÿä¸€çš„')
        return False, ''

def get_media_id(site_name, access_token, image_path):
    media_id_info_new = {}
    current_time = time.time()
    if server.common.get_cache('media_id_info', site_name):
        stored_time = server.common.get_cache('media_id_info', site_name)['stored_time']
        stored_time_datetime = datetime.fromtimestamp(stored_time)
        stored_time_str = stored_time_datetime.strftime("%Y-%m-%d %H:%M:%S")
        media_id = server.common.get_cache('media_id_info', site_name)['media_id']
        stored_modify_time = server.common.get_cache('media_id_info', site_name)['stored_modify_time']
        _LOGGER.info(f'ã€Œ{site_name}ã€ç¼“å­˜çš„å°é¢å›¾ç‰‡ä¿®æ”¹æ—¶é—´: {stored_modify_time}')
        _LOGGER.info(f'ã€Œ{site_name}ã€ä¸Šæ¬¡ä¼ å›¾åˆ°ç´ æåº“çš„æ—¶é—´: {stored_time_str}, 3å¤©æœ‰æ•ˆ, è¿‡æœŸè‡ªåŠ¨å†æ¬¡ä¸Šä¼ è·å–æ–°çš„ media_id')
        media_id_dict = {media_id}
        _LOGGER.info(f'ã€Œ{site_name}ã€å½“å‰æ­£åœ¨ä½¿ç”¨(ç¼“å­˜)çš„ ã€Œmedia_idã€: {media_id_dict}')
    else:
        _LOGGER.info(f'ã€Œ{site_name}ã€ç¼“å­˜çš„å°é¢å›¾ç‰‡ä¿®æ”¹æ—¶é—´: è¿˜æœªç¼“å­˜')
        _LOGGER.info(f'ã€Œ{site_name}ã€ä¸Šæ¬¡ä¼ å›¾åˆ°ç´ æåº“çš„æ—¶é—´: è¿˜æœªä¸Šä¼ è¿‡, 3å¤©æœ‰æ•ˆ, è¿‡æœŸè‡ªåŠ¨å†æ¬¡ä¸Šä¼ è·å–æ–°çš„ media_id')
        stored_time = current_time
        stored_modify_time = '2022-02-02 22:22:22'
        media_id = ''
    current_modify_time = os.stat(image_path).st_mtime
    current_modify_time = datetime.fromtimestamp(current_modify_time)
    current_modify_time = current_modify_time.strftime("%Y-%m-%d %H:%M:%S")
    if current_time - stored_time > 3 * 24 * 60 * 60 or not media_id or current_modify_time != stored_modify_time:
        _LOGGER.info(f'ã€Œ{site_name}ã€ä¸Šä¼ çš„å°é¢å›¾ç‰‡è¿‡æœŸæˆ–æœ‰äº†æ–°å°é¢ï¼Œå°†é‡æ–°ä¸Šä¼ å¹¶è·å–æ–°çš„ã€Œmedia_idã€')
        media_id = upload_image_and_get_media_id(site_name, access_token, image_path)
        media_id_dict = {media_id}
        _LOGGER.info(f'ã€Œ{site_name}ã€ä¸Šä¼ å°é¢å›¾ç‰‡åè·å¾—çš„æœ€æ–°ã€Œmedia_idã€: {media_id_dict}')
        media_id_info_new = {'media_id':media_id, 'stored_time':current_time, 'stored_modify_time':current_modify_time}
        server.common.set_cache('media_id_info', site_name, media_id_info_new)
    else:
        pass
    stored_media_id_info = server.common.get_cache('media_id_info', site_name)
    _LOGGER.info(f'ã€Œ{site_name}ã€å·²ç¼“å­˜çš„ ã€Œmedia_id ä¿¡æ¯ã€: {stored_media_id_info}')
    return media_id

def upload_image_and_get_media_id(site_name, access_token, image_path):
    url = "https://qyapi.weixin.qq.com/cgi-bin/media/upload"
    querystring = {"access_token": access_token, "type": "image"}
    files = {"media": ("image.gif", open(image_path, "rb"))}
    MAX_RETRIES = 3
    for i in range(MAX_RETRIES):
        try:
            response = requests.request("POST", url, params=querystring, files=files)
            break
        except requests.RequestException as e:
            _LOGGER.error(f'ã€Œ{site_name}ã€ä¸Šä¼ å°é¢å¤„ç†å¼‚å¸¸ï¼ŒåŸå› ï¼š{e}')
            time.sleep(2)
    _LOGGER.info(f'ã€Œ{site_name}ã€ä¸Šä¼ å°é¢è¿”å›ç»“æœï¼š{response.text}')
    if response.status_code == 200:
        resp_data = response.json()
        media_id = resp_data.get('media_id')
        return media_id
    else:
        _LOGGER.error(f'ã€Œ{site_name}ã€ä¸Šä¼ å°é¢å¤±è´¥ï¼ŒçŠ¶æ€ç ï¼š{response.status_code}')

def push_msg_wx(access_token, touser, agentid, wecom_title, thumb_media_id, content_source_url, wecom_digest, wecom_content, wecom_api_url):
    url = wecom_api_url + '/cgi-bin/message/send?access_token=' + access_token
    data = {
        "touser": touser,
        "msgtype": "mpnews",
        "agentid": agentid,
        "mpnews": {
            "articles": [
                {
                    "title" : wecom_title,
                    "thumb_media_id" : thumb_media_id,
                    "author" : "PTç«™å†…ä¿¡",
                    "content_source_url" : content_source_url,
                    "digest" : wecom_digest,
                    "content" : wecom_content,
                }
            ]
        },
        "safe": 0,
        "enable_id_trans": 0,
        "enable_duplicate_check": 0,
        "duplicate_check_interval": 1800
    }
    MAX_RETRIES = 3
    for i in range(MAX_RETRIES):
        try:
            r = requests.post(url, json=data)
            break
        except requests.RequestException as e:
            _LOGGER.error(f'å¤„ç†å¼‚å¸¸ï¼ŒåŸå› ï¼š{e}')
            time.sleep(2)
    if r is None:
        _LOGGER.error('è¯·æ±‚ã€Œæ¨é€æ¥å£ã€å¤±è´¥')
    else:
        return r.json()

def push_msg_mr(msg_title, message, pic_url, link_url):
    try:
        if message_to_uid:
            for _ in message_to_uid:
                try:
                    server.notify.send_message_by_tmpl('{{title}}', '{{a}}', {
                        'title': msg_title,
                        'a': message,
                        'pic_url': pic_url,
                        'link_url': link_url
                    }, to_uid=_)
                    return 'å·²æ¨é€æ¶ˆæ¯é€šçŸ¥'
                except Exception as e:
                    return f'æ¶ˆæ¯æ¨é€å¼‚å¸¸ï¼ŒåŸå› : {e}'
                    pass
        else:
            server.notify.send_message_by_tmpl('{{title}}', '{{a}}', {
                'title': msg_title,
                'a': message,
                'pic_url': pic_url,
                'link_url': link_url
            })
            return 'å·²æ¨é€æ¶ˆæ¯é€šçŸ¥'
    except Exception as e:
        return f'æ¶ˆæ¯æ¨é€å¼‚å¸¸ï¼ŒåŸå› : {e}'
        pass

def main():
    push_wx, access_token, agentid, touser, wecom_api_url = is_push_to_wx()
    sites_message_by_manual(push_wx, access_token, agentid, touser, wecom_api_url)
    site_notice(push_wx, access_token, agentid, touser, wecom_api_url)
    
