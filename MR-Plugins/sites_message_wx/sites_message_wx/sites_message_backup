#!/usr/bin/env python3
from mbot.core.plugins import plugin
from mbot.core.plugins import PluginContext, PluginMeta
from mbot.openapi import mbot_api
from typing import Dict, Any
from urllib.parse import urljoin
from bs4 import BeautifulSoup
import time
import os
# import sys
import yaml
from datetime import datetime
import re
import random
import requests
import logging
from requests.adapters import HTTPAdapter
from requests.packages.urllib3.util.retry import Retry
server = mbot_api
_LOGGER = logging.getLogger(__name__)

site_url = {
    'chdbits': 'https://chdbits.co',
    'HDHome': 'https://hdhome.org',
    'hdsky': 'https://hdsky.me',
    'hdchina': 'https://hdchina.org',
    'mteam': 'https://kp.m-team.cc',
    'lemonhd': 'https://lemonhd.org',
    'ourbits': 'https://ourbits.club',
    'ssd': 'https://springsunday.net',
    'keepfrds': 'https://pt.keepfrds.com',
    'pterclub': 'https://pterclub.com',
    'hdatmos': 'https://hdatmos.club',
    'beitai': 'https://beitai.pt',
    'soulvoice': 'https://pt.soulvoice.club',
    'audiences': 'https://audiences.me',
    'nicept': 'https://nicept.net',
    'pthome': 'https://pthome.net',
    'HDarea': 'https://hdarea.co',
    'HDTime': 'https://hdtime.org',
    'hd4fans': 'https://hd4fans.org',
    'hddolby': 'https://hddolby.com',
    'eastgame': 'https://pt.eastgame.org',
    'hdfans': 'https://hdfans.org',
    'discfan': 'https://discfan.net',
    'btschool': 'https://pt.btschool.club',
    'HDZone': 'https://hdzone.me',
    'gainbound': 'https://gainbound.net',
    'azusa': 'https://azusa.wiki',
    'ultrahd': 'https://ultrahd.net',
    'hhan': 'https://hhanclub.top',
    'hares': 'https://club.hares.top',
    'tjupt': 'https://tjupt.org',
    'leaves': 'https://leaves.red'
}

@plugin.after_setup
def after_setup(plugin_meta: PluginMeta, config: Dict[str, Any]):
    global words,user_id,wecom_proxy_url,message_to_uid,qywx_channel_extra,corpid_extra,corpsecret_extra,agentid_extra,touser_extra

    message_to_uid = config.get('uid')
    qywx_channel_extra = config.get('qywx_channel_extra')
    corpid_extra = config.get('corpid_extra')
    corpsecret_extra = config.get('corpsecret_extra')
    agentid_extra = config.get('agentid_extra')
    touser_extra = config.get('touser_extra')
    words = config.get('word_ignore')
    wecom_proxy_url = config.get('wecom_proxy_url')
    if message_to_uid:
        user_id = message_to_uid[0]
    else:
         _LOGGER.error('ã€ŒPTç«™å†…ä¿¡æ¨é€ã€è·å–æ¨é€ç”¨æˆ·å¤±è´¥ï¼Œå¯èƒ½æ˜¯è®¾ç½®äº†æ²¡ä¿å­˜æˆ–è€…è¿˜æœªè®¾ç½®')
         _LOGGER.error('ã€ŒPTç«™å†…ä¿¡æ¨é€ã€PS:è®¾ç½®ä¿å­˜åå¿…é¡»é‡å¯æ‰ä¼šç”Ÿæ•ˆï¼')
         user_id = ''

    # msg_media_id = config.get('msg_media_id')
    # notice_media_id = config.get('notice_media_id')

@plugin.config_changed
def config_changed(config: Dict[str, Any]):
    global words,user_id,wecom_proxy_url,message_to_uid,qywx_channel_extra,corpid_extra,corpsecret_extra,agentid_extra,touser_extra

    message_to_uid = config.get('uid')
    qywx_channel_extra = config.get('qywx_channel_extra')
    corpid_extra = config.get('corpid_extra')
    corpsecret_extra = config.get('corpsecret_extra')
    agentid_extra = config.get('agentid_extra')
    touser_extra = config.get('touser_extra')
    words = config.get('word_ignore')
    wecom_proxy_url = config.get('wecom_proxy_url')
    if message_to_uid:
        user_id = message_to_uid[0]
    else:
         _LOGGER.error('ã€ŒPTç«™å†…ä¿¡æ¨é€ã€è·å–æ¨é€ç”¨æˆ·å¤±è´¥ï¼Œå¯èƒ½æ˜¯è®¾ç½®äº†æ²¡ä¿å­˜æˆåŠŸæˆ–è€…è¿˜æœªè®¾ç½®')
         user_id = ''
    
@plugin.task('sites_message_wx', 'PTç«™å†…ä¿¡æ¨é€', cron_expression='0 9,19 * * *')
def task():
    time.sleep(random.randint(1, 120))
    _LOGGER.info('å¼€å§‹è·å–ç«™å†…ä¿¡å’Œå…¬å‘Š')
    main()
    _LOGGER.info('æ‰€æœ‰ç«™ç‚¹ç«™å†…ä¿¡å’Œå…¬å‘Šè·å–å®Œæˆ')

def sites_message():
    push_wx = True
    extra_flag = True
    if qywx_channel_extra:
        if corpid_extra and agentid_extra and corpsecret_extra and touser_extra:
            corpid = corpid_extra
            agentid = agentid_extra
            corpsecret = corpsecret_extra
            touser = touser_extra
            _LOGGER.error(f'è®¾ç½®çš„ç‹¬ç«‹å¾®ä¿¡åº”ç”¨å‚æ•°:ã€Œagentid: {agentid} corpid: {corpid} corpsecret: {corpsecret} touser: {touser}ã€')
        else:
            _LOGGER.error(f'è®¾ç½®çš„ç‹¬ç«‹å¾®ä¿¡åº”ç”¨å‚æ•°ä¸å®Œæ•´ï¼Œå°†é‡‡ç”¨é»˜è®¤æ¶ˆæ¯é€šé“æ¨é€')
            push_wx = False
            extra_flag = False

    if user_id and not qywx_channel_extra:
        corpid, agentid, corpsecret = get_qywx_info()
        # touser = get_qywx_user(user_id)
        touser = server.user.get(user_id).qywx_user
        _LOGGER.info(f'è·å–åˆ° MR ç³»ç»Ÿä¸»å¹²è®¾ç½®çš„çš„ä¼ä¸šå¾®ä¿¡ä¿¡æ¯:ã€Œagentid: {agentid} corpid: {corpid} corpsecret: {corpsecret} touser: {touser}ã€')
        if not agentid or not corpid or not corpsecret or not touser:
            _LOGGER.error('ä¼ä¸šå¾®ä¿¡ä¿¡æ¯è·å–å¤±è´¥æˆ–å¡«å†™ä¸å®Œæ•´')
            _LOGGER.error('åœ¨è®¾ç½®-è®¾ç½®ä¼ä¸šå¾®ä¿¡é¡µè®¾ç½®ï¼šã€Œagentidã€ï¼Œã€Œcorpidã€ï¼Œã€Œcorpsecretã€')
            _LOGGER.error('åœ¨ç”¨æˆ·ç®¡ç†é¡µè®¾ç½®å¾®ä¿¡è´¦å·ï¼Œè·å–æ–¹æ³•å‚è€ƒ: https://alanoo.notion.site/thumb_media_id-64f170f7dcd14202ac5abd6d0e5031fb')
            _LOGGER.error('æœ¬æ’ä»¶é€‰ç”¨å¾®ä¿¡é€šé“æ¨é€æ¶ˆæ¯æ•ˆæœæœ€ä½³ï¼Œä½†ç°åœ¨æ²¡è·å–åˆ°ï¼Œå°†é‡‡ç”¨é»˜è®¤æ¶ˆæ¯é€šé“æ¨é€')
            _LOGGER.error('é»˜è®¤æ¶ˆæ¯é€šé“æ¨é€ï¼šæ¯ä¸ªç«™ç‚¹å°é¢å›¾æ— æ³•ä¸€ç«™ä¸€å›¾ï¼Œéƒ½æ˜¯ç»Ÿä¸€çš„')
            push_wx = False
            # sys.exit()
    elif not user_id and not qywx_channel_extra:
        _LOGGER.error('æœªè®¾ç½®æ¨é€äººï¼Œä¹Ÿæ²¡æœ‰è®¾ç½®ç‹¬ç«‹å¾®ä¿¡åº”ç”¨å‚æ•°ï¼Œå°†é‡‡ç”¨é»˜è®¤æ¶ˆæ¯é€šé“æ¨é€')
        _LOGGER.error('é»˜è®¤æ¶ˆæ¯é€šé“æ¨é€ï¼šæ¯ä¸ªç«™ç‚¹å°é¢å›¾æ— æ³•ä¸€ç«™ä¸€å›¾ï¼Œéƒ½æ˜¯ç»Ÿä¸€çš„')
        push_wx = False

    if (push_wx or qywx_channel_extra) and extra_flag:
       
        wecom_api_url = 'https://qyapi.weixin.qq.com'
        if wecom_proxy_url:
            _LOGGER.info(f'è®¾ç½®äº†å¾®ä¿¡ç™½åå•ä»£ç†ï¼Œåœ°å€æ˜¯ï¼š{wecom_proxy_url}')
            wecom_api_url = wecom_proxy_url
        else:
            _LOGGER.info('æœªè®¾ç½®å¾®ä¿¡ç™½åå•ä»£ç†ï¼Œä½¿ç”¨å®˜æ–¹ api åœ°å€: https://qyapi.weixin.qq.com')
        access_token, push_wx = getToken(corpid, corpsecret, wecom_api_url)

    site_list = server.site.list()
    for site in site_list:
        site_id = site.site_id
        site_name = site.site_name
        if not site_id:
            continue
        if site_id not in site_url:
            continue
        _LOGGER.info(f'å¼€å§‹è·å–ã€Œ{site_name}ã€ç«™å†…ä¿¡å’Œå…¬å‘Š')
        try:
            caption_content_list,count,message_url,message_item_url,notice_list = get_nexusphp_message(site_url[site_id], site.cookie, site.proxies, site_name)
            if caption_content_list or notice_list:
                image_path = f'/data/plugins/sites_message_wx/pic/{site_id}.gif'
                try:
                    # æ£€æŸ¥ image_path æŒ‡å‘çš„æ–‡ä»¶æ˜¯å¦å­˜åœ¨
                    if not os.path.exists(image_path):
                        if caption_content_list:
                            image_path = f'/data/plugins/sites_message_wx/pic/msg_default.gif'
                        elif notice_list:
                            image_path = f'/data/plugins/sites_message_wx/pic/notice_default.gif'
                except Exception as e:
                    _LOGGER.error(f'æ£€æŸ¥æ–‡ä»¶æ˜¯å¦å­˜åœ¨æ—¶å‘ç”Ÿå¼‚å¸¸ï¼ŒåŸå› ï¼š{e}')
                if push_wx:
                    thumb_media_id = get_media_id(site_name, access_token, image_path)
            if caption_content_list:
                if count > 1:
                    wecom_title = f'ğŸ’Œ {site_name}: {count} æ¡ç«™å†…æ–°ä¿¡æ¯'
                    wecom_content_m = ''.join(caption_content_list)
                    wecom_content_m = wecom_content_m.replace('<line>', '')
                    # å»æ‰é¦–å°¾æ¢è¡Œç¬¦
                    wecom_content_m = wecom_content_m.strip('\n')
                    wecom_content = wecom_content_m.replace('\n', '<br/>')
                    wecom_digest = re.sub(r'<.*?>', '', wecom_content_m) 
                    content_source_url = message_url
                else:
                    wecom_title = caption_content_list[0].split('<line>\n')[0]
                    wecom_content = caption_content_list[0].split('<line>\n')[1]
                    wecom_content = wecom_content.strip('\n')
                    wecom_title = wecom_title.replace('\n', '')
                    wecom_title = re.sub(r'<.*?>', '', wecom_title)
                    wecom_title = f'ğŸ’Œ {site_name}: {wecom_title}'
                    wecom_title = wecom_title.replace('ğŸ’¬ ', '')
                    wecom_title = wecom_title.replace('ä½ çš„ç§å­/å¸–å­æ”¶åˆ°é­”åŠ›å€¼å¥–åŠ±', 'æ”¶åˆ°é­”åŠ›å€¼å¥–åŠ±')
                    wecom_title = wecom_title.replace('æ‚¨æ­£åœ¨ä¸‹è½½æˆ–åšç§çš„ç§å­è¢«åˆ é™¤', 'ç§å­è¢«åˆ é™¤')
                    content_source_url = message_item_url
                    wecom_digest = re.sub(r'<.*?>', '', wecom_content)
                wecom_content = wecom_content.replace('\n', '<br/>')
                # æ¨é€ç«™å†…ä¿¡
                if push_wx:
                    result = push_msg_wx(access_token, touser, agentid, wecom_title, thumb_media_id, content_source_url, wecom_digest, wecom_content, wecom_api_url)
                    _LOGGER.info(f'ã€Œ{site_name}ã€ğŸ’Œ æœ‰æ–°ç«™å†…ä¿¡ï¼Œä¼ä¸šå¾®ä¿¡æ¨é€ç»“æœ: {result}')
                else:
                    pic_url = 'https://raw.githubusercontent.com/Alano-i/wecom-notification/main/MR-Plugins/sites_message_wx/sites_message_wx/pic/msg_default.gif'
                    result = push_msg_mr(wecom_title, wecom_digest, pic_url, content_source_url)
                    _LOGGER.info(f'ã€Œ{site_name}ã€ğŸ’Œ æœ‰æ–°ç«™å†…ä¿¡ï¼Œè‡ªé€‰æ¨é€é€šé“æ¨é€ç»“æœ: {result}')
            else:
                _LOGGER.info(f'ã€Œ{site_name}ã€æ— æœªè¯»ç«™å†…ä¿¡ï¼Œæˆ–é€šè¿‡å…³é”®è¯è¿‡æ»¤åæ²¡æœ‰éœ€è¦æ¨é€çš„æ–°æ¶ˆæ¯')
            if notice_list:
                wecom_title = f'ğŸ“¢ {site_name}: {notice_list[1]}'
                wecom_content_m = f'<b><big>{notice_list[0]}</b></big>\n<small>{notice_list[2]}</small>'
                wecom_content = wecom_content_m.replace('\n', '<br/>')
                wecom_digest = re.sub(r'<.*?>', '', wecom_content_m)
                content_source_url = f'{site_url}'
                # æ¨é€å…¬å‘Š
                if push_wx:
                    result = push_msg_wx(access_token, touser, agentid, wecom_title, thumb_media_id, content_source_url, wecom_digest, wecom_content, wecom_api_url)
                    _LOGGER.info(f'ã€Œ{site_name}ã€ğŸ“¢ æœ‰æ–°å…¬å‘Šï¼Œä¼ä¸šå¾®ä¿¡æ¨é€ç»“æœ: {result}')
                else:
                    pic_url = 'https://raw.githubusercontent.com/Alano-i/wecom-notification/main/MR-Plugins/sites_message_wx/sites_message_wx/pic/notice_default.gif'
                    result = push_msg_mr(wecom_title, wecom_digest, pic_url, content_source_url)
                    _LOGGER.info(f'ã€Œ{site_name}ã€ğŸ“¢ æœ‰æ–°å…¬å‘Šï¼Œè‡ªé€‰æ¨é€é€šé“æ¨é€ç»“æœ: {result}')
            else:
                _LOGGER.info(f'ã€Œ{site_name}ã€æ— æ–°å…¬å‘Š')
        except Exception as e:
            _LOGGER.error(f'å‘ç”Ÿé”™è¯¯ï¼ŒåŸå› ï¼š{e}')
            continue

# def get_qywx_user(id):
#     result = ''
#     conn = sqlite3.connect('/data/db/main.db')
#     cursor = conn.cursor()
#     cursor.execute('SELECT qywx_user FROM user WHERE id=?', (id,))
#     result = cursor.fetchone()
#     result = result[0]
#     conn.close()
#     return result

def get_qywx_info():
    try:
        yml_file = "/data/conf/base_config.yml"
        with open(yml_file, encoding='utf-8') as f:
            yml_data = yaml.load(f, Loader=yaml.FullLoader)
        for channel in yml_data['notify_channel']:
            if channel['enable']:
                agentid = channel.get('agentid')
                corpid = channel.get('corpid')
                corpsecret = channel.get('corpsecret')
                return corpid, agentid, corpsecret
    except Exception as e:
        _LOGGER.error(f'è·å–ã€Œä¼ä¸šå¾®ä¿¡é…ç½®ä¿¡æ¯ã€é”™è¯¯ï¼Œå¯èƒ½ MR ä¸­å¡«å†™çš„ä¿¡æ¯æœ‰è¯¯æˆ–ä¸å…¨: {e}')
        pass
    return '','',''

def getToken(corpid, corpsecret, wecom_api_url):
    # è·å–access_token
    url = wecom_api_url + "/cgi-bin/gettoken?corpid=" + corpid + "&corpsecret=" + corpsecret
    MAX_RETRIES = 3
    for i in range(MAX_RETRIES):
        try:
            r = requests.get(url)
            # _LOGGER.error(f'r.json: {r.json()}')
            break
        except requests.RequestException as e:
            _LOGGER.error(f'å¤„ç†å¼‚å¸¸ï¼ŒåŸå› ï¼š{e}')
            time.sleep(2)
    if r.json()['errcode'] == 0:
        access_token = r.json()['access_token']
        return access_token, True
    else:
        _LOGGER.error('è¯·æ±‚ä¼ä¸šå¾®ä¿¡ã€Œaccess_tokenã€å¤±è´¥,è¯·æ£€æŸ¥ä¼ä¸šå¾®ä¿¡å„ä¸ªå‚æ•°æ˜¯å¦è®¾ç½®æ­£ç¡®ï¼Œå°†é‡‡ç”¨é»˜è®¤æ¶ˆæ¯é€šé“æ¨é€ï¼')
        _LOGGER.error('é»˜è®¤æ¶ˆæ¯é€šé“æ¨é€ï¼šæ¯ä¸ªç«™ç‚¹å°é¢å›¾æ— æ³•ä¸€ç«™ä¸€å›¾ï¼Œéƒ½æ˜¯ç»Ÿä¸€çš„')
        return '', False

def get_media_id(site_name, access_token, image_path):
    media_id_info_new = {}
    # è·å–å½“å‰æ—¶é—´
    current_time = time.time()
    if server.common.get_cache('media_id_info', site_name):
         # è·å–å­˜åœ¨ç¼“å­˜ä¸­çš„æ—¶é—´å’Œmedia_id
        stored_time = server.common.get_cache('media_id_info', site_name)['stored_time']
        stored_time_datetime = datetime.fromtimestamp(stored_time)
        stored_time_str = stored_time_datetime.strftime("%Y-%m-%d %H:%M:%S")
        media_id = server.common.get_cache('media_id_info', site_name)['media_id']
        stored_modify_time = server.common.get_cache('media_id_info', site_name)['stored_modify_time']
        # stored_modify_time = '2022-10-10 22:22:22'
        _LOGGER.info(f'ã€Œ{site_name}ã€ç¼“å­˜çš„å°é¢å›¾ç‰‡ä¿®æ”¹æ—¶é—´: {stored_modify_time}')
        _LOGGER.info(f'ã€Œ{site_name}ã€ä¸Šæ¬¡ä¼ å›¾åˆ°ç´ æåº“çš„æ—¶é—´: {stored_time_str}, 3å¤©æœ‰æ•ˆ, è¿‡æœŸè‡ªåŠ¨å†æ¬¡ä¸Šä¼ è·å–æ–°çš„ media_id')
        media_id_dict = {media_id}
        _LOGGER.info(f'ã€Œ{site_name}ã€å½“å‰æ­£åœ¨ä½¿ç”¨(ç¼“å­˜)çš„ ã€Œmedia_idã€: {media_id_dict}')
    else:
        _LOGGER.info(f'ã€Œ{site_name}ã€ç¼“å­˜çš„å°é¢å›¾ç‰‡ä¿®æ”¹æ—¶é—´: è¿˜æœªç¼“å­˜')
        _LOGGER.info(f'ã€Œ{site_name}ã€ä¸Šæ¬¡ä¼ å›¾åˆ°ç´ æåº“çš„æ—¶é—´: è¿˜æœªä¸Šä¼ è¿‡, 3å¤©æœ‰æ•ˆ, è¿‡æœŸè‡ªåŠ¨å†æ¬¡ä¸Šä¼ è·å–æ–°çš„ media_id')
        stored_time = current_time
        stored_modify_time = '2022-02-02 22:22:22'
        media_id = ''
    # è·å–æ–‡ä»¶çš„ä¿®æ”¹æ—¶é—´
    current_modify_time = os.stat(image_path).st_mtime
    # æ ¼å¼åŒ–æ—¶é—´ä¸º"å¹´-æœˆ-æ—¥ æ—¶åˆ†ç§’"
    current_modify_time = datetime.fromtimestamp(current_modify_time)
    current_modify_time = current_modify_time.strftime("%Y-%m-%d %H:%M:%S")
    # å¦‚æœ å½“å‰æ—¶é—´ä¸å­˜å‚¨çš„æ—¶é—´å·®å¤§äº 3 å¤©ï¼Œå°±è°ƒç”¨ä¸Šä¼ å›¾ç‰‡çš„å‡½æ•°å¹¶é‡æ–°è·å– media_id
    if current_time - stored_time > 3 * 24 * 60 * 60 or not media_id or current_modify_time != stored_modify_time:
        media_id = upload_image_and_get_media_id(site_name, access_token, image_path)
        media_id_dict = {media_id}
        _LOGGER.info(f'ã€Œ{site_name}ã€ä¸Šä¼ å°é¢å›¾ç‰‡åè·å¾—çš„æœ€æ–°ã€Œmedia_idã€: {media_id_dict}')
        media_id_info_new = {'media_id':media_id, 'stored_time':current_time, 'stored_modify_time':current_modify_time}
        server.common.set_cache('media_id_info', site_name, media_id_info_new)
    else:
        pass
    stored_media_id_info = server.common.get_cache('media_id_info', site_name)
    _LOGGER.info(f'ã€Œ{site_name}ã€å·²ç¼“å­˜çš„ ã€Œmedia_id ä¿¡æ¯ã€: {stored_media_id_info}')
    return media_id

def upload_image_and_get_media_id(site_name, access_token, image_path):
    url = "https://qyapi.weixin.qq.com/cgi-bin/media/upload"
    # /cgi-bin/material/add_material æ°¸ä¹…ç´ ææ¥å£ï¼Œä½†éœ€è¦æˆæƒï¼Œä¸çŸ¥é“è¯¥æ€ä¹ˆæˆæƒ ï¼Œ/cgi-bin/media/upload ä¸´æ—¶ç´ ææ¥å£ï¼Œ3å¤©æœ‰æ•ˆ
    querystring = {"access_token": access_token, "type": "image"}
    files = {"media": ("image.gif", open(image_path, "rb"))}
    MAX_RETRIES = 3
    for i in range(MAX_RETRIES):
        try:
            response = requests.request("POST", url, params=querystring, files=files)
            break
        except requests.RequestException as e:
            _LOGGER.error(f'å¤„ç†å¼‚å¸¸ï¼ŒåŸå› ï¼š{e}')
            time.sleep(2)
    _LOGGER.info(f'ä¸Šä¼ å°é¢è¿”å›ç»“æœï¼š{response.text}')
    # è§£æå“åº”
    if response.status_code == 200:
        resp_data = response.json()
        media_id = resp_data.get('media_id')
        return media_id
    else:
        _LOGGER.error(f'ä¸Šä¼ å›¾ç‰‡å¤±è´¥ï¼ŒçŠ¶æ€ç ï¼š{response.status_code}')

def push_msg_wx(access_token, touser, agentid, wecom_title, thumb_media_id, content_source_url, wecom_digest, wecom_content, wecom_api_url):
    # å‘é€æ¶ˆæ¯
    url = wecom_api_url + '/cgi-bin/message/send?access_token=' + access_token
    data = {
        "touser": touser,
        "msgtype": "mpnews",
        "agentid": agentid,
        "mpnews": {
            "articles": [
                {
                    "title" : wecom_title,
                    "thumb_media_id" : thumb_media_id,              # å¡ç‰‡å¤´éƒ¨å›¾ç‰‡é“¾æ¥ï¼Œæ­¤å›¾ç‰‡å­˜å‚¨åœ¨ä¼ä¸šå¾®ä¿¡ä¸­
                    "author" : "PTç«™å†…ä¿¡",                           # ç‚¹å‡»å¡ç‰‡è¿›å…¥ä¸‹çº§é¡µé¢åï¼Œæ—¶é—´æ—¥æœŸçš„æ—è¾¹çš„ä½œè€…
                    "content_source_url" : content_source_url,      # é˜…è¯»åŸæ–‡é“¾æ¥
                    "digest" : wecom_digest,                        # å›¾æ–‡æ¶ˆæ¯çš„æè¿°
                    "content" : wecom_content,                      # ç‚¹å‡»å¡ç‰‡è¿›å…¥ä¸‹çº§é¡µé¢åå±•ç¤ºçš„æ¶ˆæ¯å†…å®¹
                }
            ]
        },
        "safe": 0,
        "enable_id_trans": 0,
        "enable_duplicate_check": 0,
        "duplicate_check_interval": 1800
    }
    MAX_RETRIES = 3
    for i in range(MAX_RETRIES):
        try:
            r = requests.post(url, json=data)
            break
        except requests.RequestException as e:
            _LOGGER.error(f'å¤„ç†å¼‚å¸¸ï¼ŒåŸå› ï¼š{e}')
            time.sleep(2)
    if r is None:
        _LOGGER.error('è¯·æ±‚ã€Œæ¨é€æ¥å£ã€å¤±è´¥')
    else:
        return r.json()

# def push_msg_mr(wecom_title, wecom_digest, pic_url, content_source_url):
def push_msg_mr(msg_title, message, pic_url, link_url):
    try:
        if message_to_uid:
            for _ in message_to_uid:
                try:
                    server.notify.send_message_by_tmpl('{{title}}', '{{a}}', {
                        'title': msg_title,
                        'a': message,
                        'pic_url': pic_url,
                        'link_url': link_url
                    }, to_uid=_)
                    return 'å·²æ¨é€æ¶ˆæ¯é€šçŸ¥'
                except Exception as e:
                    return f'æ¶ˆæ¯æ¨é€å¼‚å¸¸ï¼ŒåŸå› : {e}'
                    pass
        else:
            server.notify.send_message_by_tmpl('{{title}}', '{{a}}', {
                'title': msg_title,
                'a': message,
                'pic_url': pic_url,
                'link_url': link_url
            })
            # _LOGGER.info(f'ã€Œå·²æ¨é€æ¶ˆæ¯é€šçŸ¥ã€')
            return 'å·²æ¨é€æ¶ˆæ¯é€šçŸ¥'
    except Exception as e:
                    # _LOGGER.error(f'æ¶ˆæ¯æ¨é€å¼‚å¸¸ï¼ŒåŸå› : {e}')
                    return f'æ¶ˆæ¯æ¨é€å¼‚å¸¸ï¼ŒåŸå› : {e}'
                    pass

def get_nexusphp_message(site_url, cookie, proxies, site_name):
    caption_content_list = []
    date_and_title = []
    notice_list = []
    sms_title = ''
    element_body = ''
    message_item_url = ''
    message_url = ''
    notice_url = ''
    xxx = ''
    count = 0

    notice_title_selector = 'td.text > div > a'
    notice_content_selector = 'td.text > div > div'

    unread_selector = 'td > img[alt="Unread"]'
    body_selector = 'td[colspan*="2"]'

    if proxies:
        if proxies.startswith('http'):
            proxies = {
                'http': proxies
            }
        elif proxies.startswith('socks5'):
            proxies = {
            'socks5': proxies
            }
    else:
        proxies = None

    # ç«™å†…ä¿¡
    message_url = '/messages.php?action=viewmailbox&box=1&unread=1'
    message_url = urljoin(site_url, message_url)
    headers = {
        'cookie': cookie,
    }
    session = requests.Session()
    retry = Retry(connect=3, backoff_factor=0.5)
    adapter = HTTPAdapter(max_retries=retry)
    session.mount('https://', adapter)
    response = session.request("GET", message_url, headers=headers, proxies=proxies, timeout=30).text
    # response = requests.request("GET", message_url, headers=headers, proxies=proxies, timeout=30).text
    soup = BeautifulSoup(response, 'html.parser')
    unread_list = soup.select(unread_selector)
    for unread_item in unread_list:
        td = unread_item.parent.next_sibling.next_sibling
        sms_title = td.text
        sms_title = f'ğŸ’¬ {sms_title}'
        href = td.a['href']
        message_item_url = urljoin(site_url, href)
        message_res = session.request("GET", message_item_url, headers=headers, proxies=proxies, timeout=30).text
        # message_res = requests.request("GET", message_item_url, headers=headers, proxies=proxies, timeout=30).text
        message_soup = BeautifulSoup(message_res, 'html.parser')
        element_body = message_soup.select(body_selector)[0].text.strip()
        element_body = re.sub(r'[\n\r]+', '\n', element_body)
        element_body = re.sub(r'\[.*?\]', '', element_body)
        # è®¡æ•°
        count = count + 1
        caption_content = f'<b><big>{sms_title}</b></big><line>\n<small>{element_body}</small>\n\n'
        caption_content_list.append(caption_content)
    
    # è·å–æœ€æ–°å…¬å‘Š
    # notice_url = '/index.php'
    # notice_url = urljoin(site_url, notice_url)
    notice_url = site_url
    notice_response = session.request("GET", notice_url, headers=headers, proxies=proxies, timeout=30).text    
    soup = BeautifulSoup(notice_response, 'html.parser')
    # _LOGGER.error(f'soup: {soup}')
    date_and_title = soup.select(notice_title_selector)
    if date_and_title:
        date_and_title = date_and_title[0].text.strip()
        notice_date, notice_title = date_and_title.split(' - ')
        notice_date = notice_date.replace('.', '-')
        notice_date = f'{notice_date} å…¬å‘Š'
    else:
        notice_date = ''
        notice_title = ''
        # _LOGGER.error(f'ã€Œ{site_name}ã€è·å–å…¬å‘Šå¤±è´¥')

    notice_content = soup.select(notice_content_selector)
    if notice_content:
        notice_content = notice_content[0].text.strip()
        notice_content = notice_content.strip()
        notice_content = re.sub(r'[\n\r]+', '\n', notice_content)
        notice_content = re.sub(r'\[.*?\]', '', notice_content)
    else:
        notice_content = ''
    # notice_content = 'ç ”ç©¶å†³å®šæ˜å¤©ä¸ºåº†ç¥ç«™ç‚¹100å‘¨å¹´'

    if site_name == 'ä¸å¯è¯´'  and notice_content:
        notice_content = notice_content.replace('\nã€å‚ä¸è®¨è®ºã€‘', '')
        date_and_title, notice_content = notice_content.split(' \n')
        notice_content = notice_content.strip()
        date_and_title = date_and_title.strip()
        notice_date, notice_title = date_and_title.split(' - ')
        notice_date = notice_date.replace('.', '-')
        notice_date = f'{notice_date} æ–°å…¬å‘Š'
        
    # notice_list = [notice_date, notice_title, notice_content]
    # notice_list = ['2022-12-28','ç«™ç‚¹å¼€é‚€é€šçŸ¥','ç ”ç©¶å†³å®šæ˜å¤©ä¸ºåº†ç¥ç«™ç‚¹100å‘¨å¹´ï¼Œå¼€æ”¾é‚€è¯·ï¼\n æœ›å‘¨çŸ¥ï¼Œç§¯æå‚åŠ ï¼']

    if notice_date and notice_title and notice_content:
    # if notice_list:
        new_notice = {'date':notice_date, 'title':notice_title, 'content':notice_content}
        # new_notice = {'date':notice_list[0], 'title':notice_list[1], 'content':notice_list[2]}
        old_notice = server.common.get_cache('site_notice', site_name)
        notice_list = [notice_date, notice_title, notice_content]
        if new_notice != old_notice:
            server.common.set_cache('site_notice', site_name, new_notice)
        else:
            notice_list = []
            _LOGGER.info(f'ã€Œ{site_name}ã€è·å–åˆ°çš„ã€Œæœ€æ–°å…¬å‘Šã€å’Œã€Œç¼“å­˜å…¬å‘Šã€ç›¸åŒï¼Œä¸æ¨é€')
            # _LOGGER.info(f'ã€Œ{site_name}ã€æ— æ–°å…¬å‘Š')
    else:
        _LOGGER.error(f'ã€Œ{site_name}ã€è·å–å…¬å‘Šå¤±è´¥')
        notice_list = ''
    xxx = server.common.get_cache('site_notice', site_name)
    _LOGGER.info(f'ã€Œ{site_name}ã€å…¬å‘Šçš„æœ€æ–°ç¼“å­˜ä¸º{xxx}')

    if caption_content_list:
        _LOGGER.info(f'ã€Œå…³é”®å­—è¿‡æ»¤å‰ï¼Œæœªè¯»ç«™å†…ä¿¡æ•°é‡ã€{count}')
        # å…³é”®å­—æ£€æŸ¥
        caption_content_list,count = word_ignore(site_name, caption_content_list,count)
        _LOGGER.info(f'ã€Œå…³é”®å­—è¿‡æ»¤åï¼Œæœªè¯»ç«™å†…ä¿¡æ•°é‡ã€{count}')
    # count = 3   
    # caption_content_list = ['ç«™ç‚¹å¼€é‚€é€šçŸ¥<line>\nè¿™æ˜¯å†…å®¹']
    # caption_content_list = ['<b><big>ğŸ’¬ ç­‰çº§å˜åŒ–</b></big><line>\n<small>ä½ è¢«é™çº§ä¸ºCrazy User\n\n', "<b><big>ğŸ’¬ ç§å­è¢«åˆ é™¤</b></big><line>\n<small>ä½ æ­£åœ¨ä¸‹è½½æˆ–åšç§çš„ç§å­ ' The Mortal Ascention'è¢«ç®¡ç†å‘˜åˆ é™¤ã€‚åŸå› ï¼šDupe!</small>\n\n", "<b><big>ğŸ’¬ æ¬¢è¿!</b></big><line>\n<small>ç¥è´ºä½ ï¼Œ'ç«™ç‚¹ç”¨æˆ·å'ï¼Œ\nä½ å·²æˆä¸ºOurçš„ä¸€å‘˜ï¼Œ\næˆ‘ä»¬çœŸè¯šåœ°æ¬¢è¿ä½ çš„åŠ å…¥ï¼\nè¯·åŠ¡å¿…å…ˆé˜…è¯»[url=rules.php][b]è§„åˆ™[/b][/url]ï¼Œæé—®å‰è¯·è‡ªè¡Œå‚è€ƒ[url=faq.php][b]å¸¸è§é—®é¢˜[/b][/url],æœ‰ç©ºä¹Ÿè¯·åˆ°[url=forums.php][b]è®ºå›[/b][/url]çœ‹çœ‹ã€‚ \nç¥ä½ æ„‰å¿«ã€‚</small>\n\n"]
    # notice_list = ['2022-12-28','ç«™ç‚¹å¼€é‚€é€šçŸ¥','ç ”ç©¶å†³å®šæ˜å¤©ä¸ºåº†ç¥ç«™ç‚¹100å‘¨å¹´ï¼Œå¼€æ”¾é‚€è¯·ï¼\n æœ›å‘¨çŸ¥ï¼Œç§¯æå‚åŠ ï¼']
    return caption_content_list,count,message_url,message_item_url,notice_list

def word_ignore(site_name, caption_content_list, count):
    word, hit = [], []
    if words:
        word = words.split(',')
        _LOGGER.info(f'ã€Œè®¾å®šè¿‡æ»¤å…³é”®è¯ã€{word}')
        for item in caption_content_list:
            for i in word:
                if i in item:
                    hit.append(item)
                    break
        for hit_item in hit:
            caption_content_list.remove(hit_item)
            count = count - 1
            _LOGGER.error(f'ã€Œ{site_name}ã€æœªè¯»ç«™å†…ä¿¡è§¦å‘å…³é”®è¯è¿‡æ»¤ï¼Œå°†å±è”½æ­¤æ¡æ¶ˆæ¯ï¼Œç›¸å…³æ¶ˆæ¯ä¸ä¼šæ¨é€ï¼')
        if not hit:
            _LOGGER.info(f'ã€Œ{site_name}ã€æœªè¯»ç«™å†…ä¿¡æœªè§¦å‘å…³é”®è¯è¿‡æ»¤')
    else:
        _LOGGER.info(f'æœªè®¾å®šè¿‡æ»¤å…³é”®è¯')
    return caption_content_list,count

def main():
    sites_message()
