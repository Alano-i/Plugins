#!/usr/bin/env python3
from mbot.core.plugins import plugin
from mbot.core.plugins import PluginContext, PluginMeta
from mbot.openapi import mbot_api
from typing import Dict, Any
from urllib.parse import urljoin
from bs4 import BeautifulSoup, SoupStrainer
# from pyquery import PyQuery as pq
from PIL import Image, ImageDraw, ImageFont
import time
import json
import random
import re
import os
# import shutil
import requests
import logging
import yaml
from zhdate import ZhDate
from requests.adapters import HTTPAdapter
from requests.packages.urllib3.util.retry import Retry
from datetime import datetime
server = mbot_api
loger = logging.getLogger(__name__)

plugins_name = 'ã€Œæ¯å¤©60ç§’è¯»æ‡‚ä¸–ç•Œã€'
plugins_path = '/data/plugins/daily_news'
session = requests.Session()
retry = Retry(connect=3, backoff_factor=0.5)
adapter = HTTPAdapter(max_retries=retry)
session.mount('https://', adapter)

@plugin.after_setup
def after_setup(plugin_meta: PluginMeta, config: Dict[str, Any]):
    global message_to_uid, channel, city, key, news_type
    message_to_uid = config.get('uid')
    if config.get('channel'):
        channel = config.get('channel')
        loger.info(f'{plugins_name}å·²åˆ‡æ¢é€šçŸ¥é€šé“è‡³ã€Œ{channel}ã€')
    else:
        channel = 'qywx'
    city = config.get('city')
    key = config.get('key')
    news_type = config.get('news_type')
    if not message_to_uid:
        loger.error(f'{plugins_name}è·å–æ¨é€ç”¨æˆ·å¤±è´¥ï¼Œå¯èƒ½æ˜¯è®¾ç½®äº†æ²¡ä¿å­˜æˆåŠŸæˆ–è€…è¿˜æœªè®¾ç½®')

@plugin.config_changed
def config_changed(config: Dict[str, Any]):
    global message_to_uid, channel, city, key, news_type
    message_to_uid = config.get('uid')
    if config.get('channel'):
        channel = config.get('channel')
        loger.info(f'{plugins_name}å·²åˆ‡æ¢é€šçŸ¥é€šé“è‡³ã€Œ{channel}ã€')
    else:
        channel = 'qywx'
    city = config.get('city')
    key = config.get('key')
    news_type = config.get('news_type')
    if not message_to_uid:
        loger.error(f'{plugins_name}è·å–æ¨é€ç”¨æˆ·å¤±è´¥ï¼Œå¯èƒ½æ˜¯è®¾ç½®äº†æ²¡ä¿å­˜æˆåŠŸæˆ–è€…è¿˜æœªè®¾ç½®')

@plugin.task('daily_news', 'æ¯å¤©60ç§’è¯»æ‡‚ä¸–ç•Œ', cron_expression='0 8-18,23 * * *')
def task():
    time.sleep(random.randint(1, 600))
    if datetime.now().time().hour in [8, 23]:
        server.common.set_cache('is_get_news', 'daily_news', False)
        server.common.set_cache('is_get_news', 'entertainment', False)
    if datetime.now().time().hour != 23:
        loger.info(f'{plugins_name}å®šæ—¶ä»»åŠ¡å¯åŠ¨ï¼Œå¼€å§‹è·å–æ¯æ—¥æ–°é—»å’Œå¤©æ°”')
        if main():
            loger.info(f'{plugins_name}å®šæ—¶ä»»åŠ¡è·å–æ¯æ—¥æ–°é—»å’Œå¤©æ°”å®Œæˆï¼')

# çƒ­ç‚¹æ–°é—»
def get_daily_news():
    exit_falg = False
    wecom_title = 'ğŸŒ æ¯å¤©60ç§’è¯»æ‡‚ä¸–ç•Œ'
    url = "https://api.jun.la/60s.php?format=imgapi"
    headers = {
        "Content-Type": "text/html;charset=utf-8",
        "Access-Control-Allow-Origin": "*",
        "Access-Control-Allow-Methods": "GET",
        "Access-Control-Allow-Headers": "x-requested-with, content-type"
    }
    res = session.request("GET", url, headers=headers, timeout=30)
    if res.status_code == 200:
        loger.info(f'{plugins_name}è¯·æ±‚æ¯æ—¥æ–°é—»æºï¼š{res.text}')
        image_url = json.loads(res.text)["imageBaidu"]
        image_time = json.loads(res.text)["imageTime"]
        # æ ¼å¼åŒ–æ—¥æœŸï¼Œåªä¿ç•™å¹´æœˆæ—¥
        updated_date = image_time
        # è·å–ä»Šå¤©çš„æ—¥æœŸ
        today = datetime.today().strftime("%Y-%m-%d")
        # loger.error(f"è¿è¡Œå‰è·å–æ ‡è¯†ï¼š{server.common.get_cache('is_get_news', 'daily_news')}")
        if updated_date < today:
            loger.error(f'{plugins_name}ä»Šå¤©çš„æ¯æ—¥æ–°é—»è¿˜æœªæ›´æ–°ï¼Œä¸€å°æ—¶åä¼šå†æ¬¡é‡è¯•ï¼')
            server.common.set_cache('is_get_news', 'daily_news', False)
            exit_falg = True
            return '', '', '', '', exit_falg
        elif server.common.get_cache('is_get_news', 'daily_news'):
            loger.info(f'{plugins_name}ä»Šå¤©çš„æ¯æ—¥æ–°é—»æºå·²ç»æ›´æ–°ï¼Œä½†ä»Šå¤©å·²ç»è·å–è¿‡äº†ï¼Œå°†åœ¨æ˜å¤© 8:00 å†æ¬¡è·å–ï¼')
            exit_falg = True
            return '', '', '', '', exit_falg
        else:
            news_url = image_url
            
            news_content = f'<img src="{news_url}" style="border-radius: 12px;" alt="æ¯å¤©60ç§’è¯»æ‡‚ä¸–ç•Œ" width="100%">'
            server.common.set_cache('is_get_news', 'daily_news',True)
            # news_content = f'<div style="border-radius: 12px; overflow: hidden;"><img src="{img_url}" alt="å°é¢"></div>{news_content}'
    else:
        news_content = 'è·å–çƒ­ç‚¹æ–°é—»å†…å®¹å¤±è´¥ï¼Œè¯·æ£€æŸ¥ç½‘ç»œï¼'
        news_digest = 'è·å–çƒ­ç‚¹æ–°é—»å†…å®¹å¤±è´¥ï¼Œè¯·æ£€æŸ¥ç½‘ç»œï¼'
        news_url = 'https://api.jun.la/60s.php?format=imgapi'
        loger.error('çƒ­ç‚¹æ–°é—»è·å–å¤±è´¥ï¼Œè¯·æ£€æŸ¥ç½‘ç»œï¼')
    news_digest = 'ç‚¹å‡»äº†è§£ä¸–ç•Œ'
    # loger.error(f"è¿è¡Œåè·å–æ ‡è¯†ï¼š{server.common.get_cache('is_get_news', 'daily_news')}")
    return wecom_title, news_digest, news_content, news_url, exit_falg

def get_daily_news_old():
    exit_falg = False
    wecom_title = 'ğŸŒ æ¯å¤©60ç§’è¯»æ‡‚ä¸–ç•Œ'
    url = "https://www.zhihu.com/api/v4/columns/c_1261258401923026944/items"
    headers = {
        "Content-Type": "text/html;charset=utf-8",
        "Access-Control-Allow-Origin": "*",
        "Access-Control-Allow-Methods": "GET",
        "Access-Control-Allow-Headers": "x-requested-with, content-type"
    }
    res = session.request("GET", url, headers=headers, timeout=30)
    if res.status_code == 200:
        data = json.loads(res.text)["data"]
        # æœ€æ–°æ–‡ç« æ›´æ–°æ—¥æœŸ
        updated = data[0]['updated']
        # å°†æ—¶é—´æˆ³è½¬æ¢ä¸ºæ—¥æœŸ
        date = datetime.fromtimestamp(updated)
        # æ ¼å¼åŒ–æ—¥æœŸï¼Œåªä¿ç•™å¹´æœˆæ—¥
        updated_date = date.strftime("%Y-%m-%d")
        # è·å–ä»Šå¤©çš„æ—¥æœŸ
        today = datetime.today().strftime("%Y-%m-%d")
        # loger.error(f"è¿è¡Œå‰è·å–æ ‡è¯†ï¼š{server.common.get_cache('is_get_news', 'daily_news')}")
        if updated_date < today:
            loger.error(f'{plugins_name}ä»Šå¤©çš„æ¯æ—¥æ–°é—»è¿˜æœªæ›´æ–°ï¼Œä¸€å°æ—¶åä¼šå†æ¬¡é‡è¯•ï¼')
            server.common.set_cache('is_get_news', 'daily_news', False)
            exit_falg = True
            return '', '', '', '', exit_falg
        elif server.common.get_cache('is_get_news', 'daily_news'):
            loger.info(f'{plugins_name}ä»Šå¤©çš„æ¯æ—¥æ–°é—»æºå·²ç»æ›´æ–°ï¼Œä½†ä»Šå¤©å·²ç»è·å–è¿‡äº†ï¼Œå°†åœ¨æ˜å¤© 8:00 å†æ¬¡è·å–ï¼')
            exit_falg = True
            return '', '', '', '', exit_falg
        else:
            news_url = data[0]["url"]
            news_content = data[0]["content"]
            # ä½¿ç”¨BeautifulSoupè§£æç½‘é¡µæºä»£ç 
            soup = BeautifulSoup(news_content, 'html.parser')
            p_tags = soup.find_all('p')[2:]
            news_digest = '\n\n'.join([p.text for p in p_tags])
            
            # ä½¿ç”¨pyqueryè§£æç½‘é¡µæºä»£ç 
            # doc = pq(news_content)
            # news_digest = '\n\n'.join([i.text() for i in doc('p').items()[2:]])

            news_digest = news_digest.replace('åœ¨è¿™é‡Œï¼Œæ¯å¤©60ç§’è¯»æ‡‚ä¸–ç•Œï¼', '')
            news_digest = news_digest.strip()
            if (len(news_digest)>1000):
                news_digest = news_digest[0:1000]
            news_content = re.sub(r"<figcaption>.*?</figcaption>", "", news_content, flags=re.DOTALL)
            news_content = re.sub(r"<a.*?</a>", "", news_content, flags=re.DOTALL)
            news_content = news_content.replace('<figure', '<div style="border-radius: 12px; overflow: hidden; margin-top: -22px;"><figure')
            news_content = news_content.replace('<img', '<img style="border-radius: 12px; transform: translateY(22px);"')
            news_content = news_content.replace('</figure>', '</figure></div>')
            news_content = news_content.replace('<p', '<p style="line-height: 175%; font-size:15px; margin: 10px 0px 10px 0px"')
            news_content = news_content.replace('åœ¨è¿™é‡Œï¼Œæ¯å¤©60ç§’è¯»æ‡‚ä¸–ç•Œï¼', '')
            news_content = news_content.replace('<p style="line-height: 175%; font-size:15px; margin: 10px 0px 10px 0px"></p>', '')
            # news_content = re.sub(r'<p style="line-height: 175%; font-size:15px; margin: 10px 0px 10px 0px" data-pid="(.*?)"></p>', '', news_content, flags=re.DOTALL)
            news_content = re.sub(r"<p(.*?)></p>", "", news_content, flags=re.DOTALL)
            news_content = news_content.strip()
            server.common.set_cache('is_get_news', 'daily_news',True)
            # news_content = f'<div style="border-radius: 12px; overflow: hidden;"><img src="{img_url}" alt="å°é¢"></div>{news_content}'
    else:
        news_content = 'è·å–çƒ­ç‚¹æ–°é—»å†…å®¹å¤±è´¥ï¼Œè¯·æ£€æŸ¥ç½‘ç»œï¼'
        news_digest = 'è·å–çƒ­ç‚¹æ–°é—»å†…å®¹å¤±è´¥ï¼Œè¯·æ£€æŸ¥ç½‘ç»œï¼'
        news_url = 'https://www.zhihu.com/people/mt36501'
        loger.error('çƒ­ç‚¹æ–°é—»è·å–å¤±è´¥ï¼Œè¯·æ£€æŸ¥ç½‘ç»œï¼')
    # loger.error(f"è¿è¡Œåè·å–æ ‡è¯†ï¼š{server.common.get_cache('is_get_news', 'daily_news')}")
    return wecom_title, news_digest, news_content, news_url, exit_falg

# å½±è§†å¿«è®¯
def get_entertainment_news(pic_url):
    wecom_title = 'ğŸ”¥ çƒ­ç‚¹å½±è§†å¿«è®¯'
    news_urls = [
        "https://ent.sina.cn/film",
        "https://ent.sina.cn/tv"
    ]
    news_url = news_urls[1]
    news_content = ""
    for url in news_urls:
        # è·å–ç½‘é¡µæºä»£ç 
        res = session.request("GET", url, timeout=30)
        res.encoding = "utf-8"
        html = res.text
        
        # # ä½¿ç”¨pyqueryè§£æç½‘é¡µæºä»£ç 
        # doc = pq(html)
        # h_tags = doc('h2, h3')

        # ä½¿ç”¨BeautifulSoupè§£æç½‘é¡µæºä»£ç 
        soup = BeautifulSoup(html, 'html.parser')
        h_tags = soup.find_all(["h2", "h3"])

        result = []
        for h_tag in h_tags:
            if h_tag.text not in result:
                result.append(h_tag.text)
        content = '\n\n'.join(f'{i}ã€{h_tag}' for i, h_tag in enumerate(result[:11]))
        news_content += f'{content}\n\n'
    if news_content:
        news_content = news_content.replace('0ã€\nå¨±ä¹ \nç”µè§†å‰æ²¿ \n\n', 'ğŸ“º ç”µè§†å‰æ²¿\n')
        news_content = news_content.replace('0ã€\nå¨±ä¹ \nç”µå½±å®åº“ \n\n', 'ğŸ¬ ç”µå½±å¿«è®¯\n')
        wecom_digest = news_content
        news_content = re.sub('\n+','\n',news_content)
        wecom_content = news_content.replace('\n', '<br>')
        wecom_content = wecom_content.replace('ğŸ¬ ç”µå½±å¿«è®¯', '<big><big><b>ğŸ¬ ç”µå½±å¿«è®¯</b></big></big><small>')
        wecom_content = wecom_content.replace('ğŸ“º ç”µè§†å‰æ²¿', '</small>ğŸ“º ç”µè§†å‰æ²¿')
        wecom_content = wecom_content.replace('ğŸ“º ç”µè§†å‰æ²¿', '<br><big><big><b>ğŸ“º ç”µè§†å‰æ²¿</b></big></big><small>')
        wecom_content = f'<div style="border-radius: 12px; overflow: hidden;"><img src="{pic_url}" alt="å°é¢"></div>{wecom_content}'
        server.common.set_cache('is_get_news', 'entertainment',True)
        server.common.set_cache('is_get_news', 'hour', '')
        return wecom_title, wecom_digest, wecom_content, news_url

    else:
        return wecom_title, 'å½±è§†å¿«è®¯' , 'å½±è§†å¿«è®¯', news_url

# è¯·æ±‚å¤©æ°”æ•°æ®
def get_weather():
    # city = "åŒ—äº¬"
    city_url = "https://geoapi.qweather.com/v2/city/lookup?location=" + city + "&key=" + key
    response_city = session.request("GET", city_url, timeout=30)
    city_data = response_city.json()
    # loger.error(f'city_data:{city_data}')
    daily_weather_iconDay = '100'
    if city_data['code'] == '200':
        city_data = city_data["location"][0]
        city_name = city_data["name"]
        city_id = city_data["id"]
        weather_url = "https://devapi.qweather.com/v7/weather/3d?location=" + city_id + "&key=" + key
        response = session.request("GET", weather_url, timeout=30)
        weather_data = response.json()
        if weather_data['code'] == '200':
            daily_weather_data = weather_data["daily"][0]
            daily_weather_iconDay = daily_weather_data["iconDay"]
            daily_weather_desc = daily_weather_data["textDay"]
            daily_weather_tempMin = daily_weather_data["tempMin"]
            daily_weather_tempMax = daily_weather_data["tempMax"]
            cond = f'{daily_weather_desc}  {daily_weather_tempMin}Â°~{daily_weather_tempMax}Â°'
        else:
            cond = 'é£é›¨éš¾æµ‹Â°'
            loger.error(f'{plugins_name}è·å–å¤©æ°”ä¿¡æ¯å¤±è´¥')
    else:
        city_name = 'ä½ åœ¨å¤©æ¶¯æµ·è§’'
        cond = 'é£é›¨éš¾æµ‹Â°'
        loger.error(f'{plugins_name}è·å–åŸå¸‚åå¤±è´¥,è¯·ç¡®å®š âŠã€åŸå¸‚åç§°ã€‘æ˜¯å¦è®¾ç½®æ­£ç¡®ï¼Œç¤ºä¾‹ï¼šåŒ—äº¬ã€‚â‹ã€å’Œé£å¤©æ°”ã€‘çš„ key è®¾ç½®æ­£ç¡®')
        loger.error(f'{plugins_name}ã€å’Œé£å¤©æ°”ã€‘çš„ KEY åœ¨ https://dev.qweather.com ç”³è¯·ï¼Œåˆ›å»ºé¡¹ç›®åè¿›å…¥æ§åˆ¶å°æ–°å»ºé¡¹ç›®ç„¶åæ·»åŠ  KEY')
        loger.error(f'{plugins_name}åœ¨é¡¹ç›®ç®¡ç†æ‰¾åˆ°æ–°å»ºçš„é¡¹ç›®ï¼ŒKEY ä¸‹é¢æœ‰ä¸ªæŸ¥çœ‹ï¼Œç‚¹å¼€æŸ¥çœ‹ï¼Œå³å¯æŸ¥çœ‹éœ€è¦å¡«å…¥åˆ°æ’ä»¶çš„ API KEY å€¼')
 
    return city_name, cond, daily_weather_iconDay

# è·å–å½“å¤©æ—¥æœŸ
def get_date():
    today = time.strftime("%Y-%m", time.localtime())
    today_day = time.strftime("%d", time.localtime())
    today_month = time.strftime("%m", time.localtime())
    today_year = time.strftime("%Y", time.localtime())
    return today,today_day,today_month,today_year

# è·å–å½“å¤©æ˜ŸæœŸ
def get_weekday():
    week_day_dict = {
        0: 'ä¸€',
        1: 'äºŒ',
        2: 'ä¸‰',
        3: 'å››',
        4: 'äº”',
        5: 'å…­',
        6: 'æ—¥',
    }
    date = datetime.now()
    day = date.weekday()
    weekday = week_day_dict[day]
    return weekday

# è·å–å½“å¤©å†œå†
def get_lunar_date(today_day,today_month,today_year):
    solar_date = datetime(int(today_year), int(today_month), int(today_day)) # æ–°å»ºä¸€ä¸ªé˜³å†æ—¥æœŸ
    solar_to_lunar_date = ZhDate.from_datetime(solar_date)  # é˜³å†æ—¥æœŸè½¬æ¢å†œå†æ—¥æœŸ
    # è¾“å‡ºä¸­æ–‡å†œå†æ—¥æœŸ
    lunar_date = solar_to_lunar_date.chinese()
    # äºŒé›¶äºŒäºŒå¹´ä¸‰æœˆåˆä¸€ å£¬å¯…å¹´ (è™å¹´)æå–ä¸‰æœˆåˆä¸€
    lunar_date = re.search(r'å¹´(.*?) ', lunar_date)
    if lunar_date:
        lunar_date = lunar_date.group(1)
        pattern = re.compile(r"äºŒå([ä¸€äºŒä¸‰å››äº”å…­ä¸ƒå…«ä¹])")
        lunar_date = pattern.sub(lambda m: f"å»¿{m.group(1)}", lunar_date)
    else:
        lunar_date = ''
    return lunar_date

# è·å–å¿ƒçµé¸¡æ±¤
def get_quote():
    quote_url = 'https://v1.hitokoto.cn'
    quote = session.request("GET", quote_url, timeout=30)
    response = quote.json()
    quote_content = response['hitokoto']
    line_length = 21
    lines = []
    for i in range(0, len(quote_content), line_length):
        lines.append(quote_content[i:i + line_length])
    if len(lines) > 2:
        lines[1] = lines[1][:-1] + "..."
    quote_content = '\n'.join(lines[:2])
    return quote_content

def process_weather_data(daily_weather_iconDay):
    daily_weather_iconDay = int(daily_weather_iconDay)
    # Define colors
    today_day_color = (252, 215, 102)
    line_color = (255, 255, 255, 50)
    weekday_color = (255, 255, 255)
    today_color = (255, 255, 255)
    lunar_date_color = (255, 255, 255)
    quote_content_color = (255, 255, 255, 150)
    icon_color = (255, 255, 255)
    city_color = (255, 255, 255)
    weather_desc_color = (255, 255, 255)
    # Set colors for fog, haze, and dust
    if daily_weather_iconDay in [500,501,509,510,514,515,502,511,512,513]:
        today_day_color = (169, 67, 56)
        line_color = (72, 63, 61, 50)
        weekday_color = (72, 63, 61)
        today_color = (72, 63, 61)
        lunar_date_color = (72, 63, 61)
        quote_content_color = (72, 63, 61, 150)
        icon_color = (72, 63, 61)
        city_color = (72, 63, 61)
        weather_desc_color = (72, 63, 61)
    # Define unicode values and background names
    default_weather_values = (hex(0xf1ca), 'sunny')
    weather_data = {
        99999:  default_weather_values,
        100:  (hex(0xf1cc), 'sunny'),
        101:  (hex(0xf1cd), 'cloud'),
        102:  (hex(0xf1ce), 'cloud'),
        103:  (hex(0xf1cf), 'cloud'),
        104:  (hex(0xf1d0), 'cloud'),
        300:  (hex(0xf1d5), 'rain'),
        301:  (hex(0xf1d6), 'rain'),
        302:  (hex(0xf1d7), 'rain'),
        303:  (hex(0xf1d8), 'rain'),
        304:  (hex(0xf1d9), 'rain'),
        305:  (hex(0xf1da), 'rain'),
        306:  (hex(0xf1db), 'rain'),
        307:  (hex(0xf1dc), 'rain'),
        308:  (hex(0xf1dd), 'rain'),
        309:  (hex(0xf1de), 'rain'),
        310:  (hex(0xf1df), 'rain'),
        311:  (hex(0xf1e0), 'rain'),
        312:  (hex(0xf1e1), 'rain'),
        313:  (hex(0xf1e2), 'rain'),
        314:  (hex(0xf1e3), 'rain'),
        315:  (hex(0xf1e4), 'rain'),
        316:  (hex(0xf1e5), 'rain'),
        317:  (hex(0xf1e6), 'rain'),
        318:  (hex(0xf1e7), 'rain'),
        399:  (hex(0xf1ea), 'rain'),
        400:  (hex(0xf1eb), 'snow'),
        401:  (hex(0xf1ec), 'snow'),
        402:  (hex(0xf1ed), 'snow'),
        403:  (hex(0xf1ee), 'snow'),
        404:  (hex(0xf1ef), 'snow'),
        405:  (hex(0xf1f0), 'snow'),
        406:  (hex(0xf1f1), 'snow'),
        407:  (hex(0xf1f2), 'snow'),
        408:  (hex(0xf1f3), 'snow'),
        409:  (hex(0xf1f4), 'snow'),
        410:  (hex(0xf1f5), 'snow'),
        499:  (hex(0xf1f8), 'snow'),
        500:  (hex(0xf1f9), 'fog'),
        501:  (hex(0xf1fa), 'fog'),
        502:  (hex(0xf1fb), 'haze'),
        503:  (hex(0xf1fc), 'dust'),
        504:  (hex(0xf1fd), 'dust'),
        507:  (hex(0xf1fe), 'dust'),
        508:  (hex(0xf1ff), 'dust'),
        509:  (hex(0xf200), 'haze'),
        510:  (hex(0xf201), 'haze'),
        511:  (hex(0xf202), 'haze'),
        512:  (hex(0xf203), 'haze'),
        513:  (hex(0xf204), 'haze'),
        514:  (hex(0xf205), 'fog'),
        515:  (hex(0xf206), 'fog')
    }
    bg_name = weather_data.get(daily_weather_iconDay, default_weather_values)[1]
    unicode_value = weather_data.get(daily_weather_iconDay, default_weather_values)[0]
    # bg_name, unicode_value = weather_data.get(daily_weather_iconDay, default_weather_values)
    unicode_text = chr(int(unicode_value, 16))
    return bg_name,unicode_text,today_day_color,line_color,weekday_color,today_color,lunar_date_color,quote_content_color,icon_color,city_color,weather_desc_color

# ç»˜åˆ¶å¤©æ°”å°é¢å›¾ç‰‡
def generate_image():
    # ç”»å¸ƒå¤§å°
    width = 1500
    height = 640
    weekday = get_weekday()
    # è·å–å¤©æ°”æ•°æ®
    city_name, cond, daily_weather_iconDay = get_weather()
    today,today_day,today_month,today_year = get_date()
    lunar_date = get_lunar_date(today_day,today_month,today_year)
    quote_content = get_quote()
    bg_name,unicode_text,today_day_color,line_color,weekday_color,today_color,lunar_date_color,quote_content_color,icon_color,city_color,weather_desc_color = process_weather_data(daily_weather_iconDay)

    # åŠ è½½å›¾ç‰‡
    bg = Image.open(f"{plugins_path}/bg/{bg_name}.png")

    # åˆ›å»ºç”»å¸ƒ
    image = Image.new("RGBA", (width, height), (0, 0, 255, 0))
    square = Image.new('RGBA', (width, height), (255, 255, 255, 0))
    draw = ImageDraw.Draw(image)
    # suqredraw = ImageDraw.Draw(square)
    
    # ç»˜åˆ¶å¤©æ°”èƒŒæ™¯ï¼Œè¦†ç›–æ•´ä¸ªç”»å¸ƒ
    square.paste(bg, (0, 0), mask=bg)

    # åŠ è½½å­—ä½“
    icon_font = ImageFont.truetype(f"{plugins_path}/font/qweather-icons.ttf", 85)
    num_font_Bold = ImageFont.truetype(f"{plugins_path}/font/ALIBABA_Bold.otf", 345)
    num_font_Regular = ImageFont.truetype(f"{plugins_path}/font/ALIBABA_Regular.otf", 62)
    week_font_Regular = ImageFont.truetype(f"{plugins_path}/font/zh.ttf", 140)
    text_font = ImageFont.truetype(f"{plugins_path}/font/syht.otf", 53)
    quote_font = ImageFont.truetype(f"{plugins_path}/font/syht.otf", 60)

    day_x = 85
    day_y = 35
    # ç»˜åˆ¶æ—¥æœŸ
    draw.text((day_x, day_y), today_day, fill=today_day_color, font=num_font_Bold, align='center')
    # today_day_width, today_day_height = draw.textsize(today_day, num_font_Bold)
    # è·å–æ–‡å­—å®½åº¦
    today_day_width = draw.textlength(today_day, num_font_Bold)

    # ç»˜åˆ¶ç«–çº¿
    # å®šä¹‰çº¿æ®µçš„èµ·å§‹åæ ‡å’Œç»ˆæ­¢åæ ‡
    x0, y0 = day_x + today_day_width + 25, day_y + 118
    x1, y1 = x0, y0 + 210

    # ç»˜åˆ¶ç™½è‰²çº¿æ®µï¼Œå®½åº¦ä¸º4
    draw.line((x0, y0, x1, y1), fill=line_color, width = 4)

    # ç»˜åˆ¶æ˜ŸæœŸ
    draw.text((day_x + today_day_width + 80, day_y + 95), 'æ˜Ÿ', fill=weekday_color, font=week_font_Regular)
    draw.text((day_x + today_day_width + 80 + 120 + 20, day_y + 95), 'æœŸ', fill=weekday_color, font=week_font_Regular)
    draw.text((day_x + today_day_width + 80+ 120 + 130 + 20, day_y + 95), weekday, fill=weekday_color, font=week_font_Regular)
    # ç»˜åˆ¶å¹´æœˆ
    year_month_width = draw.textlength(today, num_font_Regular)
    draw.text((day_x + today_day_width + 80, day_y + 270), today, fill=today_color, font=num_font_Regular)
    draw.text((day_x + today_day_width + 80 + year_month_width + 20 , day_y + 270), lunar_date, fill=lunar_date_color, font=text_font)

    # ç»˜åˆ¶é¸¡æ±¤
    draw.text((day_x + 20, day_y+400), quote_content, fill=quote_content_color, font=quote_font)

    # ç»˜åˆ¶å¤©æ°”å›¾æ ‡
    icon_width = draw.textlength(unicode_text, icon_font)
    draw.text((width - 105 - icon_width, day_y + 100), unicode_text, fill=icon_color, font=icon_font, align='center')
    
    # ç»˜åˆ¶åŸå¸‚
    city_width = draw.textlength(city_name, text_font)
    draw.text((width - 105 - city_width, day_y + 195), city_name, fill=city_color, font=text_font)
    # ç»˜åˆ¶å¤©æ°”è¯´æ˜
    cond_width = draw.textlength(cond, text_font)
    draw.text((width - 105 - cond_width + 18, day_y + 270), cond, fill=weather_desc_color, font=text_font)
    # ä¿å­˜å›¾ç‰‡
    image_output = Image.alpha_composite(square,image)
    image_output.save(f"{plugins_path}/weather.png")
    image_output = image_output.convert("RGB")
    image_output.save(f"{plugins_path}/weather.jpg", quality=97)
    image_path = f'{plugins_path}/weather.jpg'
    try:
        if not os.path.exists(image_path):
            image_path = f'{plugins_path}/logo.jpg'
    except Exception as e:
        loger.error(f'{plugins_name}æ£€æŸ¥æ–‡ä»¶æ˜¯å¦å­˜åœ¨æ—¶å‘ç”Ÿå¼‚å¸¸ï¼ŒåŸå› ï¼š{e}')
    return image_path, lunar_date, weekday

def upload_image_to_mr(image_path):
    pic_url = 'https://raw.githubusercontent.com/Alano-i/wecom-notification/main/MR-Plugins/daily_news/daily_news/logo.jpg'
    for i in range(3):
        try:
            pic_url = mbot_api.user.upload_img_to_cloud_by_filepath(image_path)
            loger.info(f'{plugins_name}ä¸Šä¼ åˆ° MR æœåŠ¡å™¨çš„å›¾ç‰‡ URL æ˜¯:{pic_url}')
            break
        except Exception as e:
            loger.error =  (f'{plugins_name}ç¬¬ {i+1} æ¬¡å°è¯•ï¼Œæ¶ˆæ¯æ¨é€å¼‚å¸¸ï¼Œå¤©æ°”å°é¢æœªèƒ½ä¸Šä¼ åˆ°MRæœåŠ¡å™¨,è‹¥å°è¯• 3 æ¬¡è¿˜æ˜¯å¤±è´¥ï¼Œå°†ç”¨æ’ä»¶å°é¢ä»£æ›¿ï¼ŒåŸå› : {e}')
    return pic_url

def push_msg_mr(msg_title, msg_digest, msg_content, author, link_url, image_path, pic_url, news):
    news_name = {
        'daily':'çƒ­ç‚¹æ–°é—»',
        'entertainment':'çƒ­ç‚¹å½±è§†å¿«è®¯'
    }
    msg_data = {
        'title': msg_title,
        'a': msg_digest,
        'pic_url': pic_url,
        'link_url': link_url,
        'msgtype': 'mpnews',
        'mpnews': {
            "articles": [
                {
                    "title" : msg_title,
                    "thumb_media_id" : image_path,
                    "author" : author,
                    "content_source_url" : link_url,
                    "digest" : msg_digest,
                    "content" : msg_content
                }
            ]
        }
    }
    try:
        if message_to_uid:
            for _ in message_to_uid:
                server.notify.send_message_by_tmpl('{{title}}', '{{a}}', msg_data, to_uid=_, to_channel_name = channel)
        else:
            server.notify.send_message_by_tmpl('{{title}}', '{{a}}', msg_data)
        loger.info(f'{plugins_name}å·²æ¨é€ã€Œ{news_name[news]}ã€æ¶ˆæ¯')
        return
    except Exception as e:
        loger.error(f'{plugins_name}æ¨é€ã€Œ{news_name[news]}ã€æ¶ˆæ¯å¼‚å¸¸ï¼ŒåŸå› : {e}')
    return

def main():
    loger.info(f'{plugins_name}æ¶ˆæ¯æ¨é€é€šé“ã€Œ{channel}ã€')
    exit_falg = False
    hour = server.common.get_cache('is_get_news', 'hour') or datetime.now().time().hour
    get_news_flag_entertainment = True
    get_news_flag_daily = True
    generate_image_flag = False
    if not news_type:
        loger.error(f'{plugins_name}æœªè®¾ç½®æ–°é—»ç±»å‹ï¼Œè¯·å…ˆè®¾ç½®ï¼')
        return False
    for news in news_type:
        if news == 'entertainment' and hour != 8 and server.common.get_cache('is_get_news', 'entertainment'):
            loger.info(f'{plugins_name}ä»Šå¤©å·²è·å–è¿‡å½±è§†å¿«è®¯ï¼Œå°†åœ¨æ˜å¤© 8:00 å†æ¬¡è·å–ã€‚')
            get_news_flag_entertainment = False
            continue
        if news == 'daily': 
            wecom_title, wecom_digest, wecom_content, news_url, exit_falg = get_daily_news()
            if exit_falg:
                get_news_flag_daily = False
                continue
        if not generate_image_flag:
            image_path, lunar_date, weekday = generate_image()
            generate_image_flag = True
            pic_url = upload_image_to_mr(image_path)
            author = f'å†œå†{lunar_date} æ˜ŸæœŸ{weekday}'
        if news == 'entertainment':
            wecom_title, wecom_digest, wecom_content, news_url = get_entertainment_news(pic_url)
        push_msg_mr(wecom_title, wecom_digest, wecom_content, author, news_url, image_path, pic_url, news)

    return get_news_flag_entertainment or get_news_flag_daily
